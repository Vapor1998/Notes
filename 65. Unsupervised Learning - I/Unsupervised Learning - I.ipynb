{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF-T-YCPBpaN"
   },
   "source": [
    "#**Unsupervised Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fs9RlcetCZqW"
   },
   "source": [
    "**What will you learn?**\n",
    "1. **Introduction**\n",
    "2. **Problems** : Issues with Unsupervised Learning\n",
    "3. **Types of Unsupervised Learning** : Parametric, Non-Parametric\n",
    "4. **Clustering**\n",
    "5. **Types of Clustering** : Flat, Heirarchical\n",
    "6. **K-Means for Clustering**\n",
    "7. **Sklearn's K-Means**\n",
    "8. **Self Implemented K-Means**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4czjGy8_xrm"
   },
   "source": [
    "In some pattern recognition problems, the training data consists of a set of input vectors x without any corresponding target values. The goal in such unsupervised learning problems may be to discover groups of similar examples within the data, where it is called clustering, or to determine how the data is distributed in the space, known as density estimation. To put forward in simpler terms, for a n-sampled space x1 to xn, true class labels are not provided for each sample, hence known as learning without teacher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Intro to unsupervised learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGoVrLYs_xpT"
   },
   "source": [
    "## **Problems with Unsupervised Learning**\n",
    "1. Unsupervised Learning is harder as compared to Supervised Learning tasks.\n",
    "2. How do we know if results are meaningful since no answer labels are available?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-6KjAwg_xm-"
   },
   "source": [
    "## **Why Unsupervised Learning is needed despite of these problems?**\n",
    "1. Annotating large datasets is very costly and hence we can label only a few examples manually. Example: Speech Recognition\n",
    "2. There may be cases where we don’t know how many/what classes is the data divided into. Example: Data Mining\n",
    "3. We may want to use clustering to gain some insight into the structure of the data before designing a classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mGLN45n_xk9"
   },
   "source": [
    "## **Types of Unsupervised Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SefgYJX-Bx-n"
   },
   "source": [
    "###**Parametric Unsupervised Learning**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqDOAs0cBx1R"
   },
   "source": [
    "In this case, we assume a parametric distribution of data. It assumes that sample data comes from a population that follows a probability distribution based on a fixed set of parameters. Theoretically, in a normal family of distributions, all members have the same shape and are parameterized by mean and standard deviation. That means if you know the mean and standard deviation, and that the distribution is normal, you know the probability of any future observation. Parametric Unsupervised Learning involves construction of Gaussian Mixture Models and using Expectation-Maximization algorithm to predict the class of the sample in question. This case is much harder than the standard supervised learning because there are no answer labels available and hence there is no correct measure of accuracy available to check the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqbEFnWpB2-F"
   },
   "source": [
    "###**Non-parametric Unsupervised Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGWrRCER_xiv"
   },
   "source": [
    "In non-parameterized version of unsupervised learning, the data is grouped into clusters, where each cluster(hopefully) says something about categories and classes present in the data. This method is commonly used to model and analyze data with small sample sizes. Unlike parametric models, nonparametric models do not require the modeler to make any assumptions about the distribution of the population, and so are sometimes referred to as a distribution-free method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YxejJf6_xgq"
   },
   "source": [
    "##**Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jy4Ey5a-_xeb"
   },
   "source": [
    "Clustering can be considered the most important unsupervised learning problem; so, as every other problem of this kind, it deals with finding a structure in a collection of unlabeled data. A loose definition of clustering could be “the process of organizing objects into groups whose members are similar in some way”. A cluster is therefore a collection of objects which are “similar” between them and are “dissimilar” to the objects belonging to other clusters.\n",
    "\n",
    "<img src = \"https://files.codingninjas.in/0_9ksfyh14c-aretav_-8051.png\" width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAGwuL-L_xcT"
   },
   "source": [
    "# 2 Introduction to clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNbBT8hN_xZ7"
   },
   "source": [
    "There are two types of clustering :\n",
    "1. Flat Clustering\n",
    "2. Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nCsKpQy_xYE"
   },
   "source": [
    "####**Flat Clustering**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfFZCOseRYak"
   },
   "source": [
    "Flat clustering is where we tell the model how many categories to cluster the data into. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-33UIMDsRZ5d"
   },
   "source": [
    "#### **Hierarchical Clustering**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViL85_UpRde9"
   },
   "source": [
    "Hierarchical clustering, as the name suggests is an algorithm that builds hierarchy of clusters. This algorithm starts with all the data points assigned to a cluster of their own. Then two nearest clusters are merged into the same cluster. In the end, this algorithm terminates when there is only a single cluster left.\n",
    "\n",
    "Two important things that you should know about hierarchical clustering are:\n",
    "1. This algorithm has been implemented above using bottom up approach. It is also possible to follow top-down approach starting with all data points assigned in the same cluster and recursively performing splits till each data point is assigned a separate cluster.\n",
    "2. The decision of merging two clusters is taken on the basis of closeness of these clusters. There are multiple metrics for deciding the closeness of two clusters such as Euclidean distance, Squared Euclidean distance , Manhattan distance, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Using KMeans for Flat Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKU3LgDk_xV3"
   },
   "source": [
    "##**K-Means Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Al3b0HOM_xTr"
   },
   "source": [
    "The k-means clustering method is an unsupervised machine learning technique used to identify clusters of data objects in a dataset. \n",
    "\n",
    "The basic idea is to define k centres, one for each cluster.The centroids are placed as much as possible far away from each other. The next step is to take each point belonging to a given data set and associate it to the nearest centroid. When no point is pending, the first step is completed and an early groupage is done. At this point we need to re-calculate k new centroids as barycenters of the clusters resulting from the previous step. After we have these k new centroids, a new binding has to be done between the same data set points and the nearest new centroid. A loop has been generated. As a result of this loop we may notice that the k centroids change their location step by step until no more changes are done.\n",
    "\n",
    "Finally, this algorithm aims at minimizing an objective function, in this case a squared error function. The objective function\n",
    "$$\\sum_{j=1}^{k}\\sum_{i=1}^{k}||x_i^j - c_j||^2$$\n",
    "where $$||x_i^j - c_j||$$\n",
    "\n",
    "chosen distance measure between a data point xi and the cluster centre cj, is an indicator of the distance of the n data points from their respective cluster centres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQTeOo0v_xRc"
   },
   "source": [
    "# 4. KMeans Algorithm\n",
    "\n",
    "1. Specify the number of clusters k to assign.\n",
    "2. Randomly initialize k centroids.\n",
    "3. **repeat**\n",
    "4. **expectation**: Assign each point to its closest centroid.\n",
    "5. **maximization**: Compute the centroid of each cluster.\n",
    "6. **until** the centroid position does not change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we talk abt kmeans, we are trying to get to k clusters, but these clusters are defined by their mean values. For eg, if I make k clusters and we get new datapoint p, how will we decide which cluster this datapoint will go to?  \n",
    "That will be decided by which clusters mean is closest to this datapoint p. So we will find distance between this p and mean of all clusters, and we will pick all the clusters whose mean is closest to this point p. So in a way while calculating these clusters, we will just store the mean values.  \n",
    "Now for any point we want to figure out which clusters it belongs to, just find the distance to all the means, and we would know which point belongs to which clusters.  \n",
    "So the steps of kmeans Algorithm is  \n",
    "1. **Lets Randomly pick k means value.** Which means from our dataset, we will just randomly pick k points as our mean points. \n",
    "2. **Assign each datapoint a cluster.** How do we assign? By simply seeing which mean is closest to that datapoint.  \n",
    "3. **Find the New Mean values of our clusters.**\n",
    "4. **Then we will go back to step and repeat 2 and 3.** \n",
    "We can either stop at max no of iterations or we can stop when there is nothing changing in our datapoint system which means the mean value is not changing and if the mean value is not changing once, they will not change later on as well.    \n",
    "  \n",
    "  \n",
    "So the two terminating conditions are  \n",
    "1. max iteration\n",
    "2. No more changes. \n",
    "or we can use combination of both, which means lets say we are running it for fix iteration, and we see that there is no more changes happening, we will stop.  \n",
    "  \n",
    "Its possible that we will start with really bad mean values, we pick up some mean values which are really bad, that can lead to an inefficient clustering as well. So kmeans does not necessarily means we will end up with the best clustering possible. So lots of time we will run this algorithm two or three times and take the best clustering as we get to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsCkU3_H_xPO"
   },
   "source": [
    "## 5. K-Means using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use k means we need to import kmeans \n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, it takes n_clusters as 8. This will create object for us.\n",
    "k_means = KMeans(n_clusters = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arguments**     \n",
    "**precompute_distances = 'auto'** : This is basically optimization that sklearn is doing it will try and compute the distances\n",
    "first so that we dont have to calculate again and again.    \n",
    "**init = 'k-means++'** : This is actually how do we initialize the first k points, so if we have to do it, we might just pick randomly k points, its using an algorithm called k-means++ which tries to pick these points in a way that they are spread out.  \n",
    "**max_iter = 300** : How many times we want to update our means and update the clusters.  \n",
    "**n_init = 10** : This means how many times do we want to initialize and run our algorithm again(different kinds of initialization). We will start with one initialization, run the algorithm, reach some point then we will run it again with some other initialization and eventually whichever initialization will give us best result we will use that.  \n",
    "So which clustering is better we are going to define that using function which we defined earlier which is sum of distances of each point to the mean of the cluster which they belong to. Thats the error function which we want to minimize. So if we run this algorithm 10 times, with different initializations whichever initialization gives us the best or the minimum loss function, we will pick that solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.labels_\n",
    "# labels means which points got into which cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.16666667, 1.46666667],\n",
       "       [7.33333333, 9.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also look at mean values\n",
    "k_means.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets try to plot this.\n",
    "plt.scatter(X[:, 0], X[:,1], c = k_means.labels_) # what this means is we have 6 points here and we are giving array of size 6 \n",
    "                                                  # as colors. SOme of them has 1, some of them has 0. So 1 will get the differ\n",
    "                                                  # color and 0 will get the different color.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we can see, different clusters have different color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets plot the means as well.\n",
    "plt.scatter(X[:, 0], X[:,1], c = k_means.labels_)\n",
    "plt.scatter(k_means.cluster_centers_[:, 0], k_means.cluster_centers_[:, 1]) # so we have grabbed 0th feature as x axis and 1st \n",
    "                                                                            # feature as y axis.\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, mean is represented by blue color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets give clusters to be 3 and run it again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means = KMeans(n_clusters = 3)\n",
    "k_means.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:, 0], X[:,1], c = k_means.labels_)\n",
    "plt.scatter(k_means.cluster_centers_[:, 0], k_means.cluster_centers_[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like what happened is we have one cluster which is green, its fine and then we have one cluster in purple which is also fine and it has taken one cluster which we can see is overlapped by the mean in the upper right corner which seems to be in yellow color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9XB8lTQZNptS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-AF5Nv7Nsu5"
   },
   "outputs": [],
   "source": [
    "X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "ytBxeENnNstL",
    "outputId": "84694fc6-cf54-42de-dc7b-cd0cd294d9f9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tPzaUpWNsp7"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqNGXLe-NsoO"
   },
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bxkSles1Nsd5",
    "outputId": "4fa964f6-65e6-4b2f-cb85-27b190c57cb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=2, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvoIPZfZN3x_",
    "outputId": "f10a55c8-2ee1-4a61-fbab-fa33f9745f4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLIzLoChN4oA",
    "outputId": "4945bc23-b83f-4cde-94b8-97a4dafa5271"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.16666667, 1.46666667],\n",
       "       [7.33333333, 9.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "6QQSdOqDN9Rp",
    "outputId": "10ccdfbb-e42e-4e75-bb8b-c98c31c08379"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=k_means.labels_)\n",
    "plt.scatter(k_means.cluster_centers_[:,0],k_means.cluster_centers_[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWVp3WarNsCA"
   },
   "source": [
    "##**Self-Implementation of K-Means**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tp2qTDE_xM7"
   },
   "source": [
    "Here we will code our own K-means algorithm usinf Fit and Predict functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KyUal6YuPBFz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHUuRQyvPA7x"
   },
   "outputs": [],
   "source": [
    "X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "R_bmhHGQPAwz",
    "outputId": "873db455-65bb-4492-a175-1e46ea6a04d9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Starter Code for KMeans  \n",
    "Basic intuition behind this is, lets say we have a training data, we will pass one testing data point and find its distance wrt all training datapoints, and then we will find first k nearest points, then find class of those point and then that class is the class of that particular datapoint.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit function will require the data it needs to classify, it needs the clusters which is k = 2 by default and it needs max iteration which we give it to be 100.   \n",
    "First step is to maintain list of means at all times. what all my means values right now. We will initialize this list with random values and update it.  \n",
    "Second thing we will need is an array of arrays with k entries where each entries will represent what all datapoints are in cluster1, what all datapoints are in cluster2 and so on. We need this info because the third step we do, is find the new mean values. For finding new mean values, we need to know what all points are in clusters so that we can find the new mean values.  \n",
    "So the things we need to maintain is \n",
    "1. List of means\n",
    "2. cluster information i.e. which point belongs to which cluster.    \n",
    "  \n",
    "  \n",
    "Dry Run of Fit():  \n",
    "1. Create empty mean array and append first two entries\n",
    "2. Run a loop for max iter times\n",
    "3. make an empty cluster array and add k no of empty array in it.\n",
    "4. Go through each datapoint. \n",
    "5. find distances of that point from all means. \n",
    "6. find the mimimum distances and find the mean value which is at mimimum distance.  \n",
    "7. Append that datapoint to that cluster  \n",
    "8. For next part, we need to find new mean values so we find new mean values of k clusters, and check if the mean is same or not, if not then we will make change = True.  \n",
    "9. else we will change the mean, if the mean is same, we will break then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing the fit function.\n",
    "def fit(data, k = 2, max_iter = 100):\n",
    "    means = []\n",
    "    # 1. we will have to randomly initialize the means\n",
    "    # for this we will pick the first k datapoints and assign them to be initial means.\n",
    "    for i in range(k):\n",
    "        means.append(data[i])\n",
    "    #2. now we need to run max iter times \n",
    "    for i in range(max_iter):\n",
    "        #3. first thing we do is assign the datapoints to the cluster that they belong to.\n",
    "        # create empty clusters.\n",
    "        clusters = []\n",
    "        for i in range(k):\n",
    "            #4.everytime we start new iteration, we are going to start with empty clusters coz we are going to\n",
    "            # reassign all the datapoints to clusters. So we are going to have some means, assign some datapoints to some \n",
    "            # clusters, calculate the new means and then assign the datapoints to new clusters.\n",
    "            clusters.append([])\n",
    "        \n",
    "        #5. so we need to go through each datapoints.\n",
    "        for point in data:\n",
    "            #6. so we need to first find the distance to all the mean values\n",
    "            # so we will go through all the means and find the distances of all m wrt the point that we have and\n",
    "            # point is np array. point - m will give us elementwise subtraction. \n",
    "            distances = [((point - m)**2).sum() for m in means]\n",
    "            \n",
    "            # and find the min distance\n",
    "            minDistances = min(distances)\n",
    "            \n",
    "            # and find the mean for which we got the min distance --> lets say mean is l.\n",
    "            l = distances.index(minDistances)\n",
    "\n",
    "            # Add this point to cluster l.\n",
    "            clusters[l].append(point)\n",
    "            \n",
    "            # As we are done with this, we are done with the first part which is assign the datapoints to clusters that they \n",
    "            # belong to.\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        #7. second step we are supposed to do is calculate the mean values.\n",
    "        # if there is no change in mean value at all, we will return\n",
    "        change = False\n",
    "        for j in range(k):\n",
    "            # if we dont provide axis =0 it will find the average of cluster j of all the points and combines the x1 and x2 \n",
    "            # values as well.\n",
    "            new_mean = np.average(clusters[j], axis=0)\n",
    "            # below means if new mean is not equal to old mean value, we will make change = true.\n",
    "            if not np.array_equal(means[j], new_mean):\n",
    "                change = True\n",
    "            means[j] = new_mean\n",
    "        if not change:\n",
    "            break\n",
    "                \n",
    "        return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 2.]), array([4.9 , 5.88])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict will tell us which point belongs to which cluster.\n",
    "def predict(test_data, means):\n",
    "    predictions = []\n",
    "    for point in test_data:\n",
    "        # find distances to all mean values.\n",
    "        distances = [((point - m)**2).sum() for m in means]\n",
    "        \n",
    "        # and find the min distance\n",
    "        minDistances = min(distances)\n",
    "            \n",
    "        # and find the mean for which we got the min distance --> lets say mean is l.\n",
    "        l = distances.index(minDistances)\n",
    "        \n",
    "        # add this point to cluster l\n",
    "        predictions.append(l)\n",
    "    return predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = fit(X)\n",
    "predict(X, means)\n",
    "# thats what we got in sklearn as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Implementing KMeans Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Means:\n",
    "    def __init__(self):\n",
    "        print(\"constructor\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit (self, data, k = 2, max_iter = 100):\n",
    "        means = []\n",
    "        # randomly initialize the means\n",
    "        for i in range(k):\n",
    "            means.append(data[i])\n",
    "        for i in range(max_iter):\n",
    "            # assign the data points to the cluster that they belong to\n",
    "            # create empty clusters        \n",
    "            clusters = []\n",
    "            for j in range(k):\n",
    "                clusters.append([])\n",
    "            for point in data:\n",
    "                # find distance to all the mean values\n",
    "                distances = [((point - m)**2).sum() for m in means]\n",
    "                # find the min distance\n",
    "                minDistance = min(distances)\n",
    "                # find the mean for which we got the minimum distance --> l\n",
    "                l = distances.index(minDistance)\n",
    "                # add this point to cluster l\n",
    "                clusters[l].append(point)\n",
    "\n",
    "            # calculate the new mean values\n",
    "            change = False\n",
    "            for j in range(k):\n",
    "                new_mean = np.average(clusters[j], axis=0)\n",
    "                if not np.array_equal(means[j], new_mean):\n",
    "                    change = True\n",
    "                means[j] = new_mean\n",
    "            if not change:\n",
    "                break\n",
    "        return means\n",
    "    \n",
    "    def predict(self, test_data, means):\n",
    "        predictions = []\n",
    "        for point in test_data:\n",
    "           # find distance to all the mean values\n",
    "            distances = [((point - m)**2).sum() for m in means]\n",
    "            # find the min distance\n",
    "            minDistance = min(distances)\n",
    "            # find the mean for which we got the minimum distance --> l\n",
    "            l = distances.index(minDistance)\n",
    "            # add this point to cluster l\n",
    "            predictions.append(l)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructor\n"
     ]
    }
   ],
   "source": [
    "# creating the object of class\n",
    "kmeans =  K_Means()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating fit function\n",
    "means = kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.predict(X, means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Passing K and Iterations Manually**  \n",
    "Ideally we dont pass means as argument in predict function.  \n",
    "and K and max_iter should be in constructor.  \n",
    "Similarly we want means to be used by predict function.  \n",
    "  \n",
    "In a nutshell, we will pass k and means and max_iteras parameter, so we create class for it and pass it inside object of class. \n",
    "So change jo hoga, har jagah means, max_iter and k ke pehle self.k and self.means and self.max_iter hojaayega. Thats it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Means:\n",
    "    def __init__(self, k = 2, max_iter = 100):\n",
    "        print(\"constructor\")\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "        \n",
    "    def fit (self, data):\n",
    "        self.means = []\n",
    "        # randomly initialize the means\n",
    "        for i in range(self.k):\n",
    "            self.means.append(data[i])\n",
    "        for i in range(self.max_iter):\n",
    "            # assign the data points to the cluster that they belong to\n",
    "            # create empty clusters        \n",
    "            clusters = []\n",
    "            for j in range(self.k):\n",
    "                clusters.append([])\n",
    "            for point in data:\n",
    "                # find distance to all the mean values\n",
    "                distances = [((point - m)**2).sum() for m in self.means]\n",
    "                # find the min distance\n",
    "                minDistance = min(distances)\n",
    "                # find the mean for which we got the minimum distance --> l\n",
    "                l = distances.index(minDistance)\n",
    "                # add this point to cluster l\n",
    "                clusters[l].append(point)\n",
    "\n",
    "            # calculate the new mean values\n",
    "            change = False\n",
    "            for j in range(self.k):\n",
    "                new_mean = np.average(clusters[j], axis=0)\n",
    "                if not np.array_equal(self.means[j], new_mean):\n",
    "                    change = True\n",
    "                self.means[j] = new_mean\n",
    "            if not change:\n",
    "                break\n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        predictions = []\n",
    "        for point in test_data:\n",
    "           # find distance to all the mean values\n",
    "            distances = [((point - m)**2).sum() for m in self.means]\n",
    "            # find the min distance\n",
    "            minDistance = min(distances)\n",
    "            # find the mean for which we got the minimum distance --> l\n",
    "            l = distances.index(minDistance)\n",
    "            # add this point to cluster l\n",
    "            predictions.append(l)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructor\n"
     ]
    }
   ],
   "source": [
    "# creating the object of class\n",
    "kmeans =  K_Means(2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating fit function\n",
    "means = kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.16666667, 1.46666667]), array([7.33333333, 9.        ])]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qfy61f2RoN9"
   },
   "source": [
    "####**Class of K-Means**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "ObHfdMb1PAlV"
   },
   "outputs": [],
   "source": [
    "class K_Means:\n",
    "    def __init__(self, k = 2, max_iter = 100):\n",
    "        print(\"constructor\")\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "        \n",
    "    def fit (self, data):\n",
    "        self.means = []\n",
    "        # randomly initialize the means\n",
    "        for i in range(self.k):\n",
    "            self.means.append(data[i])\n",
    "        for i in range(self.max_iter):\n",
    "            # assign the data points to the cluster that they belong to\n",
    "            # create empty clusters        \n",
    "            clusters = []\n",
    "            for j in range(self.k):\n",
    "                clusters.append([])\n",
    "            for point in data:\n",
    "                # find distance to all the mean values\n",
    "                distances = [((point - m)**2).sum() for m in self.means]\n",
    "                # find the min distance\n",
    "                minDistance = min(distances)\n",
    "                # find the mean for which we got the minimum distance --> l\n",
    "                l = distances.index(minDistance)\n",
    "                # add this point to cluster l\n",
    "                clusters[l].append(point)\n",
    "\n",
    "            # calculate the new mean values\n",
    "            change = False\n",
    "            for j in range(self.k):\n",
    "                new_mean = np.average(clusters[j], axis=0)\n",
    "                if not np.array_equal(self.means[j], new_mean):\n",
    "                    change = True\n",
    "                self.means[j] = new_mean\n",
    "            if not change:\n",
    "                break\n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        predictions = []\n",
    "        for point in test_data:\n",
    "           # find distance to all the mean values\n",
    "            distances = [((point - m)**2).sum() for m in self.means]\n",
    "            # find the min distance\n",
    "            minDistance = min(distances)\n",
    "            # find the mean for which we got the minimum distance --> l\n",
    "            l = distances.index(minDistance)\n",
    "            # add this point to cluster l\n",
    "            predictions.append(l)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xhve9R3jPOl5",
    "outputId": "f86a47ca-c1f2-4b1a-f861-f2fb47ab6f00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructor\n"
     ]
    }
   ],
   "source": [
    "kmeans = K_Means(2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "dsrRmTycPOkO"
   },
   "outputs": [],
   "source": [
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dxZdafTMPObp",
    "outputId": "a7acf549-d612-42e3-df63-6abd803b231d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxGxVlW_PYx0",
    "outputId": "e637e8cd-edc0-49a5-927d-2bf2e9d98a1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.16666667, 1.46666667]), array([7.33333333, 9.        ])]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBaD14wX_xK1"
   },
   "source": [
    "##**Applications of Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGYOaiep_xIg"
   },
   "source": [
    "Clustering has a large no. of applications spread across various domains. Some of the most popular applications of clustering are:\n",
    "1. Recommendation engines\n",
    "2. Market segmentation\n",
    "3. Social network analysis\n",
    "4. Search result grouping\n",
    "5. Medical imaging\n",
    "6. Image segmentation\n",
    "7. Anomaly detection"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Unsupervised Learning 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
