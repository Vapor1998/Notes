{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly, let's explain Gradient Boosting with steps and include the relevant formulas in LaTeX format:\n",
    "\n",
    "**Step 1: Initialize the Model**\n",
    "\n",
    "Initialize the model with a simple prediction, often the mean (for regression) or the mode (for classification) of the target variable. This initial prediction is represented as:\n",
    "\n",
    "$$\n",
    "F_0(x) = \\text{initial prediction}\n",
    "$$\n",
    "\n",
    "**Step 2: Calculate Residuals (or Pseudo-Residuals)**\n",
    "\n",
    "Compute the residuals (the differences between the actual target values and the current predictions) or pseudo-residuals (in the case of classification problems). These residuals represent the errors that the current model makes. For regression problems, the residual for each data point $i$ is given by:\n",
    "\n",
    "$$\n",
    "r_i = y_i - F_{t-1}(x_i)\n",
    "$$\n",
    "\n",
    "For classification problems with a loss function like cross-entropy, the pseudo-residual for each data point $i$ is given by:\n",
    "\n",
    "$$\n",
    "r_i = -\\frac{\\partial L(y_i, F_{t-1}(x_i))}{\\partial F_{t-1}(x_i)} = $$\n",
    "\n",
    "\n",
    "\n",
    "where $L$ is the loss function.\n",
    "\n",
    "**Step 3: Fit a Weak Learner (Decision Tree)**\n",
    "\n",
    "Train a weak learner (usually a decision tree with limited depth) on the dataset, but instead of predicting the target values, predict the residuals or pseudo-residuals from step 2. The weak learner for iteration $t$ is denoted as $h_t(x)$.\n",
    "\n",
    "**Step 4: Update the Model**\n",
    "\n",
    "Add a fraction (learning rate, often denoted as \"η\") of the predictions from the weak learner to the current model's predictions. This step helps prevent overfitting and allows for gradual model improvement. The update formula is:\n",
    "\n",
    "$$\n",
    "F_t(x) = F_{t-1}(x) + \\eta \\cdot h_t(x)\n",
    "$$\n",
    "\n",
    "**Step 5: Repeat Steps 2-4**\n",
    "\n",
    "Repeat the process for a specified number of iterations (boosting rounds) or until a certain level of accuracy is achieved. In each iteration, you calculate new residuals based on the errors of the current model and fit a new weak learner to correct those errors.\n",
    "\n",
    "**Step 6: Final Prediction**\n",
    "\n",
    "The final prediction is the sum of the initial model's prediction and the predictions made by each weak learner, weighted by the learning rate. This combination of multiple weak learners creates a strong predictive model that is better at capturing complex relationships in the data. The final prediction is represented as:\n",
    "\n",
    "$$\n",
    "\\hat{y}(x) = F_T(x) = F_0(x) + \\sum_{t=1}^{T} \\eta \\cdot h_t(x)\n",
    "$$\n",
    "\n",
    "Here are some additional details and considerations:\n",
    "\n",
    "- **Loss Function:** The choice of loss function determines how the residuals or pseudo-residuals are calculated in step 2. The loss function is represented as $L(y, F(x))$.\n",
    "\n",
    "- **Hyperparameters:** Gradient Boosting has hyperparameters, including the learning rate $\\eta$, the number of boosting rounds (T), and the depth and complexity of the weak learners (trees). These hyperparameters are tuned to optimize model performance.\n",
    "\n",
    "- **Regularization:** Various techniques can be used to regularize Gradient Boosting models, such as limiting the depth of trees or using early stopping to prevent overfitting.\n",
    "\n",
    "- **Feature Importance:** Feature importance can be assessed by measuring how often features are used in the weak learners and how much they contribute to reducing the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Step 1: Initialize the Model**\n",
    "\n",
    "| Iteration (t) | Initial Prediction (F_t(x)) |\n",
    "|----------------|-----------------------------|\n",
    "| 0              | 4.0                         |\n",
    "\n",
    "**Step 2: Calculate Residuals**\n",
    "\n",
    "| Data Point (i) | Actual y | Predicted F_0(x) | Residual (r_i) |\n",
    "|-----------------|----------|-------------------|-----------------|\n",
    "| 1               | 2        | 4.0               | -2.0            |\n",
    "| 2               | 4        | 4.0               | 0.0             |\n",
    "| 3               | 5        | 4.0               | 1.0             |\n",
    "| 4               | 4        | 4.0               | 0.0             |\n",
    "| 5               | 5        | 4.0               | 1.0             |\n",
    "\n",
    "**Step 3: Fit a Weak Learner (Decision Tree)**\n",
    "\n",
    "The decision tree splits based on the feature X at a threshold of 3.5:\n",
    "\n",
    "| Data Point (i) | Actual y | Predicted F_0(x) | Residual (r_i) | Weak Learner (h_1(x)) |\n",
    "|-----------------|----------|-------------------|-----------------|-------------------------|\n",
    "| 1               | 2        | 4.0               | -2.0            | -2.0                    |\n",
    "| 2               | 4        | 4.0               | 0.0             | 0.0                     |\n",
    "| 3               | 5        | 4.0               | 1.0             | 0.5                     |\n",
    "| 4               | 4        | 4.0               | 0.0             | 0.5                     |\n",
    "| 5               | 5        | 4.0               | 1.0             | 0.5                     |\n",
    "\n",
    "**Step 4: Update the Model (Iteration 1)**\n",
    "\n",
    "Update the model using a learning rate (η) of 0.1:\n",
    "\n",
    "| Iteration (t) | Updated Prediction (F_t(x)) |\n",
    "|----------------|------------------------------|\n",
    "| 0              | 4.0                          |\n",
    "| 1              | 4.0 - (0.1 * h_1(x))         |\n",
    "\n",
    "For each data point:\n",
    "\n",
    "- For data point 1: \n",
    "  ```\n",
    "  F_1(x_1) = 4.0 + (0.1 * (-2.0)) = 3.8\n",
    "  ```\n",
    "- For data point 2: \n",
    "  ```\n",
    "  F_1(x_2) = 4.0 + (0.1 * 0.0) = 4.0\n",
    "  ```\n",
    "- For data point 3: \n",
    "  ```\n",
    "  F_1(x_3) = 4.0 + (0.1 * 0.5) = 4.05\n",
    "  ```\n",
    "- For data point 4: \n",
    "  ```\n",
    "  F_1(x_4) = 4.0 + (0.1 * 0.5) = 4.05\n",
    "  ```\n",
    "- For data point 5: \n",
    "  ```\n",
    "  F_1(x_5) = 4.0 + (0.1 * 0.5) = 4.05\n",
    "  ```\n",
    "\n",
    "**Step 5: Repeat Steps 2-4 for Iteration 2 (Not Shown Here)**\n",
    "\n",
    "In practice, you would continue with more iterations, but for simplicity, we'll stop after one iteration.\n",
    "\n",
    "**Step 6: Final Prediction**\n",
    "\n",
    "The final prediction is the sum of the initial model's prediction and the predictions made by each weak learner, weighted by the learning rate (η):\n",
    "\n",
    "| Final Prediction (F(x)) |\n",
    "|--------------------------|\n",
    "| F(x) = F_0(x) + (0.1 * h_1(x)) |\n",
    "\n",
    "For any given value of X, you can calculate the final prediction using this formula.\n",
    "\n",
    "Certainly! Let's calculate the final prediction based on the steps we've performed. We'll use the formula for the final prediction:\n",
    "\n",
    "$$\n",
    "F(x) = F_0(x) + (0.1 \\cdot h_1(x))\n",
    "$$\n",
    "\n",
    "We've already calculated the updated predictions for each data point in Iteration 1. Now, let's calculate the final prediction for a specific value of X.\n",
    "\n",
    "Suppose we want to calculate the final prediction for $X = 6$:\n",
    "\n",
    "$$\n",
    "F(6) = F_0(6) + (0.1 \\cdot h_1(6))\n",
    "$$\n",
    "\n",
    "We'll calculate it step by step:\n",
    "\n",
    "1. Calculate $F_0(6)$ (the initial prediction):\n",
    "   $$\n",
    "   F_0(6) = 4.0 \\quad \\text{(initial prediction)}\n",
    "   $$\n",
    "\n",
    "2. Calculate $h_1(6)$ (the prediction from the weak learner):\n",
    "   - Since $X = 6$ falls into the \"X > 3.5\" branch of the decision tree in Iteration 1:\n",
    "     $$\n",
    "     h_1(6) = 0.5 \\quad \\text{(prediction from the weak learner)}\n",
    "     $$\n",
    "\n",
    "3. Now, calculate the final prediction for $X = 6$:\n",
    "   $$\n",
    "   F(6) = 4.0 + (0.1 \\cdot 0.5) = 4.05\n",
    "   $$\n",
    "\n",
    "So, the final prediction for $X = 6$ is $F(6) = 4.05$.\n",
    "\n",
    "You can use this approach to calculate the final prediction for any other value of X by plugging it into the formula and following similar calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo Algorithm  \n",
    "1. Initialize model with constant value $$F_0(x) = argmin_{\\gamma}(\\sum_{i=1}^{n}L(y, \\gamma) )$$  \n",
    "2. Iterate m = 1 to M:\n",
    "    1. Compute Pseudo Residuals :   $$r_i = - [\\ \\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}]\\ _{F(x) = F_{m-1}(x)}  \\ for  \\ i = 1....., n$$\n",
    "    2. Fit a base learner (or weak learner, e.g. tree) closed under scaling  $h_{m}(x)$ to pseudo-residuals, i.e. train it using the training set ${(x_i, r_{im})}$\n",
    "    3. Compute multiplier $\\gamma_m$ by solving the following one dimensional optimization problem:$$ \\gamma_m = argmin_{\\gamma} \\sum_{x_i \\in R_{jm}} L(y_{i}, F_{m-1}(x_i) + \\gamma ) \\ for \\ j = 1.....J_m $$\n",
    "    4. Update the model: $$F_m = F_{m-1}(x) + \\gamma_m h_m(x)$$\n",
    "3. Output F_M(x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Experience      | Degree   | Salary(y)         | \n",
    "|-----------------|----------|-------------------|\n",
    "| 2               | BE       | 50K               |\n",
    "| 3               | PHD      | 70K               | \n",
    "| 4               | MAST     | 60K               | \n",
    "\n",
    "STEP 1:  $$F_0(x) = argmin_{\\gamma}(\\sum_{i=1}^{n}L(y, \\gamma) )$$ means we need to find out $\\hat{y}$ such that whole loss should reduce.  \n",
    "So the loss function is $$Loss = \\sum_{i=1}^{n} \\frac{1}{2}(y - \\hat{y})^2$$   \n",
    "Now there are three records, so = $$\\frac{1}{2}(50 - \\hat{y})^2 \\frac{1}{2}(70 - \\hat{y})^2 \\frac{1}{2}(60 - \\hat{y})^2$$  \n",
    "Now, if we want to find out the predicted value such that we want to minimize the loss, we need to do first order derivative with respect to $\\hat{y}$, because we want to find $\\gamma$ or $\\hat{y}$. After deriving, we get $\\hat{y} = 60$.  \n",
    "The first step is done and the table becomes\n",
    "\n",
    "| Experience      | Degree   | Salary(y)         | $\\hat{y}$ |\n",
    "|-----------------|----------|-------------------|-----------|\n",
    "| 2               | BE       | 50K               | 60K       |   \n",
    "| 3               | PHD      | 70K               | 60K       |\n",
    "| 4               | MAST     | 60K               | 60K       |  \n",
    "\n",
    "Now step 2(A) says we need to find the pseudo residual which is $$r_i = - [\\ \\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}]\\ _{F(x) = F_{m-1}(x)}  \\ for  \\ i = 1....., n \\ \\ \\ .... (1)$$ \n",
    " Here it says derivative of loss($L$) with respect to $F(x_i)$. Now in previous step our model is $F_0(x)$. So initially the loss function is $$Loss = \\sum_{i=1}^{n} \\frac{1}{2}(y - \\hat{y})^2$$.  \n",
    " So if we find the derivative of this loss wrt $\\hat{y}$, we get $$= \\ \\frac{2}{2}(y - \\hat{y})(-1)$$\n",
    " $$= \\ -y+\\hat{y}$$ $$= \\ -(y - \\hat{y})$$ $$\\frac{\\partial L}{\\partial \\hat{y}} = -(y - \\hat{y})$$  Taking minus on both sides, we get $$-\\frac{\\partial L}{\\partial \\hat{y}} = (y - \\hat{y}) \\ \\ \\ .... (2)$$.  \n",
    " Now if we compare (1) and (2), it is same $$-\\frac{\\partial L}{\\partial \\hat{y}} = - [\\ \\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}] .... \\ \\because \\ \\hat{y} \\ is \\ output \\ of \\ prev \\ model \\ F_0(x)$$ the above expressions are same. So we can say $$r_{im} = (y - \\hat{y})$$.  \n",
    "After calculating residuals we get    \n",
    "\n",
    "| Experience      | Degree   | Salary(y)         | $\\hat{y}$ | $r_{im}$|\n",
    "|-----------------|----------|-------------------|-----------|---------|\n",
    "| 2               | BE       | 50K               | 60K       |-10      |\n",
    "| 3               | PHD      | 70K               | 60K       | 10      |\n",
    "| 4               | MAST     | 60K               | 60K       |  0      |  \n",
    "  \n",
    "Now in the next step, we fit a decision tree with $r_{im}$ as dependent feature.   \n",
    "In third step, which is Compute multiplier $\\gamma_m$ by solving the following one dimensional optimization problem:$$ \\gamma_m = argmin_{\\gamma} \\sum_{x_i \\in R_{jm}} L(y_{i}, F_{m-1}(x_i) + \\gamma ) \\ for \\ j = 1.....J_m $$. \n",
    "Compare the above equation to the first step. Here, the $\\gamma$ from first step is replaced with $F_{m-1}(x_i) + \\gamma$. Here, $F_{m-1}(x_i)$ is the output of previous model. So here, we need to find $\\gamma$ which minimizes the loss.   \n",
    "We can find these particular loss as $$ \\sum_{i=1}^n \\frac{1}{2}(y_i - (60 + \\hat{y}))^2$$. To minimize the loss, we do the first order derivative of the above loss function.  \n",
    "Now next step is to update the model, to update it, we use the formula $$F_m = F_{m-1}(x) + \\gamma_m h_m(x)$$   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/OBmgEba.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one input column, and one output column, Machine Learning models are basically functions. They are relations between x and y.  \n",
    "We can write it as $$y = f(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:21:37.008178Z",
     "iopub.status.busy": "2023-10-20T19:21:37.007840Z",
     "iopub.status.idle": "2023-10-20T19:21:37.044436Z",
     "shell.execute_reply": "2023-10-20T19:21:37.043574Z",
     "shell.execute_reply.started": "2023-10-20T19:21:37.008150Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {'R&D Spend' : [165, 101, 29], \"Administration\":[137, 92, 127], \"Marketing Spend\":[472, 250, 201], \"Profit\":[192, 144, 91]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:21:37.046420Z",
     "iopub.status.busy": "2023-10-20T19:21:37.045966Z",
     "iopub.status.idle": "2023-10-20T19:21:37.347543Z",
     "shell.execute_reply": "2023-10-20T19:21:37.346099Z",
     "shell.execute_reply.started": "2023-10-20T19:21:37.046396Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:21:37.349537Z",
     "iopub.status.busy": "2023-10-20T19:21:37.349092Z",
     "iopub.status.idle": "2023-10-20T19:21:37.356319Z",
     "shell.execute_reply": "2023-10-20T19:21:37.355310Z",
     "shell.execute_reply.started": "2023-10-20T19:21:37.349509Z"
    }
   },
   "outputs": [],
   "source": [
    "df=  pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:21:37.359774Z",
     "iopub.status.busy": "2023-10-20T19:21:37.359310Z",
     "iopub.status.idle": "2023-10-20T19:21:37.389768Z",
     "shell.execute_reply": "2023-10-20T19:21:37.389011Z",
     "shell.execute_reply.started": "2023-10-20T19:21:37.359738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165</td>\n",
       "      <td>137</td>\n",
       "      <td>472</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>92</td>\n",
       "      <td>250</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>127</td>\n",
       "      <td>201</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend  Profit\n",
       "0        165             137              472     192\n",
       "1        101              92              250     144\n",
       "2         29             127              201      91"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have 3 rows, and X is the first three columns while Y is Profit.  \n",
    "So, we will say for the 0th row, we will say the 0th row is the Spend of the first startup, 1st row for the second startup and so on. And we will say 0th row profit is the profit of first startup, 1st row profit for second startup and so on. Now the loss function which we take in the first steps has a prerequisite which is we need to have a loss function which we can differentiate at every point or it is differentiable.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Calculating the first step, it says \n",
    "# 1. Initialize model with constant Value\n",
    "$$F_0(x) = argmin_{\\gamma} \\sum_{i=1}^n L(y_i, \\gamma)$$\n",
    "Now, the loss function we use is least square, which is $$\\sum_{i=1}^n (y_i - \\hat{y_i})^2$$   \n",
    "Here in this, we will multiply it by 1/2 , because of mathematical convenience. Sometimes we do some things with math from which you dont get much difference, but it makes small mathematical step easy. So here we will differentiate this loss function, we will apply chain rule to it, so the 2 of the square will cancel out with the half, which will save the extra effort of the step of calculation. A question may pop out that something may go wrong after adding half in it, no nothing goes wrong.   \n",
    "Visiting the intuition of the model, it is $$F(x) = F_0(x) + F_1(x) + F_2(x) + F_3(x) .......... + F_n(x) $$\n",
    "By comparing this with the step, we need to find $F_0(x)$.  \n",
    "  \n",
    "Coming back to the step, we have the loss function $$\\frac{1}{2}\\sum_{i=1}^n (y_i - \\hat{y_i})^2$$, we can see instead of $\\hat{y}$, we are using $\\gamma$ which is same.  \n",
    "Rewriting the whole step we can write step 1 as $$f_0(x) = argmin_{\\gamma} \\frac{1}{2} \\sum_{i=1}^n L(y_i - \\gamma)^2$$  \n",
    "Above expression means we need value of $\\gamma$ such that the value of the above whole expression is minimum. So we differentiate whole term wrt $\\gamma$.   \n",
    "$$\\frac{d f_0(x)}{d \\gamma} = \\frac{d}{d\\gamma} \\frac{1}{2}\\sum_{i=1}^n(y_i - \\gamma)^2$$  \n",
    "$$= \\frac{2}{2} \\sum_{i=1}^n (y_i - \\gamma) \\frac{d}{d\\gamma}(y_i - \\gamma)$$  \n",
    "$$= -\\sum_{i=1}^n(y_i - \\gamma) $$  \n",
    "Taking minus inside, expression becomes, $$\\sum_{i=1}^{n}(\\gamma - y_i) = 0$$  \n",
    "  \n",
    "Now taking the value from dataset and calculating $\\gamma$, we get $$\\sum_{i=0}^2 (\\gamma - y_i) = 0  => (\\gamma - 192) + (\\gamma - 144) + (\\gamma - 91) = 0$$ \n",
    "$$ 3\\gamma = 192 + 144 + 91$$  \n",
    "  \n",
    "$$\\gamma = \\frac{192 + 144+ 91}{3}$$  \n",
    "  \n",
    "So the code of above step becomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:21:37.392434Z",
     "iopub.status.busy": "2023-10-20T19:21:37.392051Z",
     "iopub.status.idle": "2023-10-20T19:21:37.402481Z",
     "shell.execute_reply": "2023-10-20T19:21:37.400663Z",
     "shell.execute_reply.started": "2023-10-20T19:21:37.392406Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"f0(x)\"] = df['Profit'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:21:37.404655Z",
     "iopub.status.busy": "2023-10-20T19:21:37.404330Z",
     "iopub.status.idle": "2023-10-20T19:21:37.421240Z",
     "shell.execute_reply": "2023-10-20T19:21:37.420363Z",
     "shell.execute_reply.started": "2023-10-20T19:21:37.404624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>Profit</th>\n",
       "      <th>f0(x)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165</td>\n",
       "      <td>137</td>\n",
       "      <td>472</td>\n",
       "      <td>192</td>\n",
       "      <td>142.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>92</td>\n",
       "      <td>250</td>\n",
       "      <td>144</td>\n",
       "      <td>142.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>127</td>\n",
       "      <td>201</td>\n",
       "      <td>91</td>\n",
       "      <td>142.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend  Profit       f0(x)\n",
       "0        165             137              472     192  142.333333\n",
       "1        101              92              250     144  142.333333\n",
       "2         29             127              201      91  142.333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-*+963\n",
    ".r+-We calculated $F_0(x)$, the rest of the functions above which are $f_1(x)$, $f_2(x)$ ... and so on are the Decision Trees, and we are calculating them inside loop.  \n",
    "Now we move to step 2.1 which says   \n",
    "For m = 1 to M: \n",
    "1. For i = 1, 2, .... N compute $$r_{im} = - [\\ \\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}]\\ _{F = F_{m-1}} $$  \n",
    "Here i means row number and m means decision tree number. So $r_{21}$ means calculating 2nd row value of first decision tree. So we have to calculate r for each row.  \n",
    "So to calculate for $r_{i1}$, we write formula as $$r_{i1} = - [\\ \\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}]\\ _{F = F_{0}} $$  \n",
    "We have 3 rows, so we will calculate $r_{11}$, $r_{21}$, $r_{31}$. We will read $r_{11}$ as residual of 1st row of first decision tree and so on.    \n",
    "So the above loss function says we are differentiating it wrt $f(x_i)$.  \n",
    "We have already established above that $f(x_i)$ = $\\hat{y_i}$ which is output of our model. So replacing $f(x_i)$ with $\\hat{y_i}$, we get $$r_{i1} = - [\\ \\frac{\\partial L(y_i, \\hat{y_i})}{\\partial \\hat{y_i}}]\\ _{F = F_{0}} $$ $$r_{i1} = - [\\ \\frac{\\partial}{\\partial \\hat{y_i}}L(y_i, \\hat{y_i})]\\ _{F = F_{0}} $$   \n",
    "Our loss function was $$\\frac{1}{2}\\sum_{i=1}^n (y_i - \\hat{y_i})^2$$  \n",
    "So here, we will replace the loss function on the above equation, except we will not use the sigma because we are calculating the residual of each row separately so theres no need to add sigma.  \n",
    "So by changing, we get $$r_{i1} = - [\\ \\frac{\\partial}{\\partial \\hat{y_i}} \\frac{1}{2}(y_i -\\hat{y_i})^2]\\ _{F = F_{0}} $$ After performing differentiation of above equation, we get $$ = [\\ y_i - \\hat{y_i} ]\\ _{F = F_0}$$   \n",
    "  \n",
    "$$ = [\\ y_i - F(x_i) ]\\ _{F = F_0} \\ ... \\ \\because \\ \\hat{y_i} = f(x_i)$$    \n",
    "  \n",
    "$$r_{i1} =  y_i - F_0(x_i) ... \\ replacing \\  f(x_i) \\  with  \\ f_0(x_i)$$  \n",
    "\n",
    "So for calculating, $$r_{11} = y_1 - f_0(x_1) = 192 - 142$$ $$r_{21} = y_2 - f_0(x_2) = 144 - 142$$ $$r_{31} = y_3 - f_0(x_3) = 91 - 142$$  \n",
    "Code will look like "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:21:37.422906Z",
     "iopub.status.busy": "2023-10-20T19:21:37.422559Z",
     "iopub.status.idle": "2023-10-20T19:21:37.437290Z",
     "shell.execute_reply": "2023-10-20T19:21:37.435812Z",
     "shell.execute_reply.started": "2023-10-20T19:21:37.422877Z"
    }
   },
   "outputs": [],
   "source": [
    "df['ri1'] = df['Profit'] - df['f0(x)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:21:37.439538Z",
     "iopub.status.busy": "2023-10-20T19:21:37.438715Z",
     "iopub.status.idle": "2023-10-20T19:21:37.454789Z",
     "shell.execute_reply": "2023-10-20T19:21:37.453582Z",
     "shell.execute_reply.started": "2023-10-20T19:21:37.439506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>Profit</th>\n",
       "      <th>f0(x)</th>\n",
       "      <th>ri1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165</td>\n",
       "      <td>137</td>\n",
       "      <td>472</td>\n",
       "      <td>192</td>\n",
       "      <td>142.333333</td>\n",
       "      <td>49.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>92</td>\n",
       "      <td>250</td>\n",
       "      <td>144</td>\n",
       "      <td>142.333333</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>127</td>\n",
       "      <td>201</td>\n",
       "      <td>91</td>\n",
       "      <td>142.333333</td>\n",
       "      <td>-51.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend  Profit       f0(x)        ri1\n",
       "0        165             137              472     192  142.333333  49.666667\n",
       "1        101              92              250     144  142.333333   1.666667\n",
       "2         29             127              201      91  142.333333 -51.333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-16T19:51:13.283697Z",
     "iopub.status.busy": "2023-10-16T19:51:13.283373Z",
     "iopub.status.idle": "2023-10-16T19:51:13.290962Z",
     "shell.execute_reply": "2023-10-16T19:51:13.289386Z",
     "shell.execute_reply.started": "2023-10-16T19:51:13.283672Z"
    }
   },
   "source": [
    "Next Step says we need to fit Decision Tree which is step 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:21:37.458052Z",
     "iopub.status.busy": "2023-10-20T19:21:37.457405Z",
     "iopub.status.idle": "2023-10-20T19:21:39.097372Z",
     "shell.execute_reply": "2023-10-20T19:21:39.096135Z",
     "shell.execute_reply.started": "2023-10-20T19:21:37.458014Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor \n",
    "dt1 = DecisionTreeRegressor(max_depth = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:21:39.099456Z",
     "iopub.status.busy": "2023-10-20T19:21:39.099034Z",
     "iopub.status.idle": "2023-10-20T19:21:39.121749Z",
     "shell.execute_reply": "2023-10-20T19:21:39.120545Z",
     "shell.execute_reply.started": "2023-10-20T19:21:39.099422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1.fit(df.iloc[:, 0:3].values, df['ri1'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:21:39.124323Z",
     "iopub.status.busy": "2023-10-20T19:21:39.123553Z",
     "iopub.status.idle": "2023-10-20T19:21:39.346814Z",
     "shell.execute_reply": "2023-10-20T19:21:39.345529Z",
     "shell.execute_reply.started": "2023-10-20T19:21:39.124278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0.75, 'x[0] <= 65.0\\nsquared_error = 1701.556\\nsamples = 3\\nvalue = -0.0'),\n",
       " Text(0.25, 0.25, 'squared_error = 0.0\\nsamples = 1\\nvalue = -51.333'),\n",
       " Text(0.75, 0.25, 'squared_error = 576.0\\nsamples = 2\\nvalue = 25.667')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plot_tree(dt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now completing the rest of 2.2 which says,    \n",
    "# 2.2\n",
    "Fit a regression tree to the targets $r_{im}$ giving terminal regions $R_{jm}$, j= 1,2,...$J_m$   \n",
    "Now, what is Terminal Region?  \n",
    "We plot a scatter plot of data. And lets say if we run a decision tree with max_depth = 1, it will cut the dataset in two parts, i.e. it will plot a line. Like the one in below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lets say if we give max depth = 2, it will create two lines, like the one below.  \n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRbwKgBv_6Lx31wsglGU60AxHhflmx9AZim8g&usqp=CAU)  \n",
    "We can see, because of two lines, the graph is divided into three parts.   \n",
    "**In a nutshell, the graph will be cut into parts equal to number of leaf nodes or max_depth**. When you fit decision tree, we get a value which we can see in the decision tree graph we plotted, that is the output or prediction of decision tree.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the value of the first output is -51.3. The other is 25.667, how is this calculated? It is calculated the mean of the first two points. So what decision tree does is that it creates terminal region and whatever points exists in the region, it calculates the mean of it.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating step 2.3, which says  \n",
    "for j = 1,2,....$J_m$ compute $$\\gamma_m = argmin_{\\gamma} \\sum_{x_i \\in R_{jm}} L(y_{i}, F_{m-1}(x_i) + \\gamma )$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are currently working on dt1, so we need to find $\\gamma_{j1}$. Inside $\\gamma_{j1}$ we have two terminal region2 $\\gamma_{j11}$ and  $\\gamma_{21}$, two terminal regions where $\\gamma_{11}$ has one point and $\\gamma_{21}$ has two points to predict.  \n",
    "So first, we find $\\gamma_{11}$ which can be written as $$ \\gamma_{11} = argmin_{\\gamma} \\sum_{x_i \\in R_{11}} L(y_{i}, F_{m-1}(x_i) + \\gamma )$$  \n",
    "So we are finding the output of first leaf from the above dt graph.  \n",
    "Here we are finding $\\gamma_{11}$, lets understand what is $x_i \\in R_{11}$? It means we need to take from $x_i$ which falls under $R_{11}$ or leaf 1.   \n",
    "So finding the point, we dont have to add summation since there is only one point in this leaf. So it can be written as $$ \\gamma_{11} =  argmin_{\\gamma} \\frac{1}{2}(y_i - (f_0(x_i) + \\gamma))^2$$  \n",
    "To find gamma, we need to differentiate wrt $\\gamma$, So we need to find $\\frac{dL}{d\\gamma}$ which is $$\\frac{dL}{d\\gamma} = \\frac{1}{2} * 2 (y_i - (f_0(x) + \\gamma)) \\frac{d}{d\\gamma}(y_i - f_0(x) - \\gamma) $$ $$ = -(y_i - f_0(x) - \\gamma)$$ $$y_i - f_0(x) - \\gamma = 0 ... \\ multiplying \\ both \\ sides \\  with \\ minus$$   \n",
    "So $\\gamma{11}$ = $$\\gamma_{11} = 91 - 142 - \\gamma$$ $$\\gamma = 91 - 142 $$ $$\\gamma = -51$$ which -51 is same as dt1 output.  \n",
    "  \n",
    "For finding $\\gamma_{21}$, we need to add sum because there are two points which lies under second leaf or terminal.  $$\\gamma_{21} = argmin_{\\gamma} \\sum_{x \\in R_{21}} L(y_i - f_0(x_i) + \\gamma)$$  $$= argmin_{\\gamma} \\sum_{i=1}^2 (y_i - (f_0(x_i)+ \\gamma))^2$$ $$= -\\sum_{i=1}^2(y_i - f_0(x_i) - \\gamma) = 0$$ $$\\sum_{i=1}^2(y_i - f_0(x_i) - \\gamma) = 0  ... multiplying \\ both \\ sides \\ by \\ -$$  \n",
    "Lets calculate for both the leafs.  \n",
    "$$y_1 - f_0(x_1)-\\gamma+ y_2-f_0(x_2) - \\gamma = 0$$  \n",
    "Putting values in it.  \n",
    "$$192 - 142 - \\gamma + 144 - 142 - \\gamma = 0$$\n",
    "$$= 52 - 2\\gamma = 0$$\n",
    "$$\\gamma = 26$$  \n",
    "One thing we realized is we are getting the same output as dt1 after calculating step 2.3. We got this coz the loss function is least square, if we used a different loss function, we wouldve got the different value.  \n",
    "If you're using least square, you can consider the dt output as the output of step 2.3 as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now calculating step 2.4, which is \n",
    "$$f_m(x) = f_{m-1}(x) +  \\sum \\limits_{j=1}^{J_m}  \\gamma_{jm}I(x \\in R_{jm})$$  \n",
    "which can be written as $$f_1(x) = f_0(x) + dt$$ which means the expression $\\sum \\limits_{j=1}^{J_m}  \\gamma_{jm}I(x \\in R_{jm})$ is either previous step output or the decision tree output.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say you are coming on second iteration, the expression can be written as $$f_2(x) = f_1(x) + dt2$$ which means the addition of the previous model which is  $f_0(x) + dt$ and second decision tree or the output of step 2.3 and the same step repeats on each iteration. When the iteration is completed, we return $f_m(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
