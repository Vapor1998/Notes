{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets,preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.. _breast_cancer_dataset:',\n",
       " '',\n",
       " 'Breast cancer wisconsin (diagnostic) dataset',\n",
       " '--------------------------------------------',\n",
       " '',\n",
       " '**Data Set Characteristics:**',\n",
       " '',\n",
       " '    :Number of Instances: 569',\n",
       " '',\n",
       " '    :Number of Attributes: 30 numeric, predictive attributes and the class',\n",
       " '',\n",
       " '    :Attribute Information:',\n",
       " '        - radius (mean of distances from center to points on the perimeter)',\n",
       " '        - texture (standard deviation of gray-scale values)',\n",
       " '        - perimeter',\n",
       " '        - area',\n",
       " '        - smoothness (local variation in radius lengths)',\n",
       " '        - compactness (perimeter^2 / area - 1.0)',\n",
       " '        - concavity (severity of concave portions of the contour)',\n",
       " '        - concave points (number of concave portions of the contour)',\n",
       " '        - symmetry',\n",
       " '        - fractal dimension (\"coastline approximation\" - 1)',\n",
       " '',\n",
       " '        The mean, standard error, and \"worst\" or largest (mean of the three',\n",
       " '        worst/largest values) of these features were computed for each image,',\n",
       " '        resulting in 30 features.  For instance, field 0 is Mean Radius, field',\n",
       " '        10 is Radius SE, field 20 is Worst Radius.',\n",
       " '',\n",
       " '        - class:',\n",
       " '                - WDBC-Malignant',\n",
       " '                - WDBC-Benign',\n",
       " '',\n",
       " '    :Summary Statistics:',\n",
       " '',\n",
       " '    ===================================== ====== ======',\n",
       " '                                           Min    Max',\n",
       " '    ===================================== ====== ======',\n",
       " '    radius (mean):                        6.981  28.11',\n",
       " '    texture (mean):                       9.71   39.28',\n",
       " '    perimeter (mean):                     43.79  188.5',\n",
       " '    area (mean):                          143.5  2501.0',\n",
       " '    smoothness (mean):                    0.053  0.163',\n",
       " '    compactness (mean):                   0.019  0.345',\n",
       " '    concavity (mean):                     0.0    0.427',\n",
       " '    concave points (mean):                0.0    0.201',\n",
       " '    symmetry (mean):                      0.106  0.304',\n",
       " '    fractal dimension (mean):             0.05   0.097',\n",
       " '    radius (standard error):              0.112  2.873',\n",
       " '    texture (standard error):             0.36   4.885',\n",
       " '    perimeter (standard error):           0.757  21.98',\n",
       " '    area (standard error):                6.802  542.2',\n",
       " '    smoothness (standard error):          0.002  0.031',\n",
       " '    compactness (standard error):         0.002  0.135',\n",
       " '    concavity (standard error):           0.0    0.396',\n",
       " '    concave points (standard error):      0.0    0.053',\n",
       " '    symmetry (standard error):            0.008  0.079',\n",
       " '    fractal dimension (standard error):   0.001  0.03',\n",
       " '    radius (worst):                       7.93   36.04',\n",
       " '    texture (worst):                      12.02  49.54',\n",
       " '    perimeter (worst):                    50.41  251.2',\n",
       " '    area (worst):                         185.2  4254.0',\n",
       " '    smoothness (worst):                   0.071  0.223',\n",
       " '    compactness (worst):                  0.027  1.058',\n",
       " '    concavity (worst):                    0.0    1.252',\n",
       " '    concave points (worst):               0.0    0.291',\n",
       " '    symmetry (worst):                     0.156  0.664',\n",
       " '    fractal dimension (worst):            0.055  0.208',\n",
       " '    ===================================== ====== ======',\n",
       " '',\n",
       " '    :Missing Attribute Values: None',\n",
       " '',\n",
       " '    :Class Distribution: 212 - Malignant, 357 - Benign',\n",
       " '',\n",
       " '    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian',\n",
       " '',\n",
       " '    :Donor: Nick Street',\n",
       " '',\n",
       " '    :Date: November, 1995',\n",
       " '',\n",
       " 'This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.',\n",
       " 'https://goo.gl/U2Uwz2',\n",
       " '',\n",
       " 'Features are computed from a digitized image of a fine needle',\n",
       " 'aspirate (FNA) of a breast mass.  They describe',\n",
       " 'characteristics of the cell nuclei present in the image.',\n",
       " '',\n",
       " 'Separating plane described above was obtained using',\n",
       " 'Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree',\n",
       " 'Construction Via Linear Programming.\" Proceedings of the 4th',\n",
       " 'Midwest Artificial Intelligence and Cognitive Science Society,',\n",
       " 'pp. 97-101, 1992], a classification method which uses linear',\n",
       " 'programming to construct a decision tree.  Relevant features',\n",
       " 'were selected using an exhaustive search in the space of 1-4',\n",
       " 'features and 1-3 separating planes.',\n",
       " '',\n",
       " 'The actual linear program used to obtain the separating plane',\n",
       " 'in the 3-dimensional space is that described in:',\n",
       " '[K. P. Bennett and O. L. Mangasarian: \"Robust Linear',\n",
       " 'Programming Discrimination of Two Linearly Inseparable Sets\",',\n",
       " 'Optimization Methods and Software 1, 1992, 23-34].',\n",
       " '',\n",
       " 'This database is also available through the UW CS ftp server:',\n",
       " '',\n",
       " 'ftp ftp.cs.wisc.edu',\n",
       " 'cd math-prog/cpo-dataset/machine-learn/WDBC/',\n",
       " '',\n",
       " '.. topic:: References',\n",
       " '',\n",
       " '   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction ',\n",
       " '     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on ',\n",
       " '     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,',\n",
       " '     San Jose, CA, 1993.',\n",
       " '   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and ',\n",
       " '     prognosis via linear programming. Operations Research, 43(4), pages 570-577, ',\n",
       " '     July-August 1995.',\n",
       " '   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques',\n",
       " '     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) ',\n",
       " '     163-171.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer.DESCR.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breast_cancer.data\n",
    "Y = breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2            3           4   \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    14.127292   19.289649   91.969033   654.889104    0.096360   \n",
       "std      3.524049    4.301036   24.298981   351.914129    0.014064   \n",
       "min      6.981000    9.710000   43.790000   143.500000    0.052630   \n",
       "25%     11.700000   16.170000   75.170000   420.300000    0.086370   \n",
       "50%     13.370000   18.840000   86.240000   551.100000    0.095870   \n",
       "75%     15.780000   21.800000  104.100000   782.700000    0.105300   \n",
       "max     28.110000   39.280000  188.500000  2501.000000    0.163400   \n",
       "\n",
       "               5           6           7           8           9   ...  \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  ...   \n",
       "mean     0.104341    0.088799    0.048919    0.181162    0.062798  ...   \n",
       "std      0.052813    0.079720    0.038803    0.027414    0.007060  ...   \n",
       "min      0.019380    0.000000    0.000000    0.106000    0.049960  ...   \n",
       "25%      0.064920    0.029560    0.020310    0.161900    0.057700  ...   \n",
       "50%      0.092630    0.061540    0.033500    0.179200    0.061540  ...   \n",
       "75%      0.130400    0.130700    0.074000    0.195700    0.066120  ...   \n",
       "max      0.345400    0.426800    0.201200    0.304000    0.097440  ...   \n",
       "\n",
       "               20          21          22           23          24  \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    16.269190   25.677223  107.261213   880.583128    0.132369   \n",
       "std      4.833242    6.146258   33.602542   569.356993    0.022832   \n",
       "min      7.930000   12.020000   50.410000   185.200000    0.071170   \n",
       "25%     13.010000   21.080000   84.110000   515.300000    0.116600   \n",
       "50%     14.970000   25.410000   97.660000   686.500000    0.131300   \n",
       "75%     18.790000   29.720000  125.400000  1084.000000    0.146000   \n",
       "max     36.040000   49.540000  251.200000  4254.000000    0.222600   \n",
       "\n",
       "               25          26          27          28          29  \n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  \n",
       "mean     0.254265    0.272188    0.114606    0.290076    0.083946  \n",
       "std      0.157336    0.208624    0.065732    0.061867    0.018061  \n",
       "min      0.027290    0.000000    0.000000    0.156500    0.055040  \n",
       "25%      0.147200    0.114500    0.064930    0.250400    0.071460  \n",
       "50%      0.211900    0.226700    0.099930    0.282200    0.080040  \n",
       "75%      0.339100    0.382900    0.161400    0.317900    0.092080  \n",
       "max      1.058000    1.252000    0.291000    0.663800    0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.DataFrame(X)\n",
    "X_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,Y_train,Y_val = model_selection.train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting column of ones in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = np.append(X_train_scaled,np.ones(X_train_scaled.shape[0]).reshape(-1,1),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 31), (31,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape,X_train_scaled[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(agg):\n",
    "    \n",
    "    return 1/(1+np.exp(-agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(X_train,Y_train,m):\n",
    "    \n",
    "    cost_ = 0\n",
    "    N = X_train.shape[0]\n",
    "    for i in range(N):\n",
    "        agg = (X_train[i]*m).sum()\n",
    "        h = sigmoid(agg)\n",
    "        cost = -Y_train[i]*np.log(h) - (1-Y_train[i])*np.log(1-h)\n",
    "        cost_ += cost\n",
    "    \n",
    "    return cost_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(X_train,Y_train,lr,m):\n",
    "    \n",
    "    N = X_train.shape[0]\n",
    "    slope_m = np.zeros(X_train.shape[1])\n",
    "    for i in range(N):\n",
    "        agg = (X_train[i]*m).sum()\n",
    "        h = sigmoid(agg)\n",
    "        slope_m+=(-1/N)*(Y_train[i]-h)*X_train[i]\n",
    "        \n",
    "    m = m - lr*slope_m\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train,Y_train,epochs=100,lr=0.01):\n",
    "    \n",
    "    m = np.zeros(X_train.shape[1])\n",
    "    cost_array = []\n",
    "    unit = epochs//100\n",
    "    for i in range(epochs):\n",
    "        m = step_gradient(X_train,Y_train,lr,m)\n",
    "        cost_ = cost(X_train,Y_train,m)\n",
    "        cost_array.append(cost_)\n",
    "        if i%unit==0:\n",
    "            print(\"Epoch:{}, Cost:{}\".format(i,cost_))\n",
    "    \n",
    "    return m,cost_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test,m):\n",
    "    \n",
    "    y_pred = []\n",
    "    N = X_test.shape[0]\n",
    "    for i in range(N):\n",
    "        agg = (X_test[i]*m).sum()\n",
    "        h = sigmoid(agg)\n",
    "        if h>=0.5:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "            \n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(Y_test,Y_pred):\n",
    "    \n",
    "    correct = 0\n",
    "    N = Y_test.shape[0]\n",
    "    correct = (Y_test==Y_pred).sum()\n",
    "    \n",
    "    return (correct/N)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Cost:286.3505027978212\n",
      "Epoch:50, Cost:134.91268940444675\n",
      "Epoch:100, Cost:101.64017135508816\n",
      "Epoch:150, Cost:85.68728096112487\n",
      "Epoch:200, Cost:75.90642542501567\n",
      "Epoch:250, Cost:69.15141432825259\n",
      "Epoch:300, Cost:64.14547874366905\n",
      "Epoch:350, Cost:60.25617014499554\n",
      "Epoch:400, Cost:57.12879451918688\n",
      "Epoch:450, Cost:54.547098288889416\n",
      "Epoch:500, Cost:52.371037853743054\n",
      "Epoch:550, Cost:50.505632087154545\n",
      "Epoch:600, Cost:48.88403287470685\n",
      "Epoch:650, Cost:47.457732753683786\n",
      "Epoch:700, Cost:46.19061549140847\n",
      "Epoch:750, Cost:45.05519275863792\n",
      "Epoch:800, Cost:44.03014127881995\n",
      "Epoch:850, Cost:43.09864322480064\n",
      "Epoch:900, Cost:42.24723901237948\n",
      "Epoch:950, Cost:41.465016285585094\n",
      "Epoch:1000, Cost:40.74302503015964\n",
      "Epoch:1050, Cost:40.07384818500386\n",
      "Epoch:1100, Cost:39.45128132262497\n",
      "Epoch:1150, Cost:38.87009021159143\n",
      "Epoch:1200, Cost:38.32582489911193\n",
      "Epoch:1250, Cost:37.81467541987679\n",
      "Epoch:1300, Cost:37.333358577559224\n",
      "Epoch:1350, Cost:36.87902820922893\n",
      "Epoch:1400, Cost:36.4492033996027\n",
      "Epoch:1450, Cost:36.041710560464416\n",
      "Epoch:1500, Cost:35.65463632462722\n",
      "Epoch:1550, Cost:35.28628895142748\n",
      "Epoch:1600, Cost:34.93516648764239\n",
      "Epoch:1650, Cost:34.59993033219938\n",
      "Epoch:1700, Cost:34.279383155251956\n",
      "Epoch:1750, Cost:33.97245035015744\n",
      "Epoch:1800, Cost:33.678164370390014\n",
      "Epoch:1850, Cost:33.39565143658677\n",
      "Epoch:1900, Cost:33.12412020193853\n",
      "Epoch:1950, Cost:32.86285204442857\n",
      "Epoch:2000, Cost:32.61119271743891\n",
      "Epoch:2050, Cost:32.36854514003598\n",
      "Epoch:2100, Cost:32.1343631478399\n",
      "Epoch:2150, Cost:31.908146057047293\n",
      "Epoch:2200, Cost:31.689433919653577\n",
      "Epoch:2250, Cost:31.477803368522785\n",
      "Epoch:2300, Cost:31.272863967703525\n",
      "Epoch:2350, Cost:31.074254997070476\n",
      "Epoch:2400, Cost:30.881642611602587\n",
      "Epoch:2450, Cost:30.694717324867163\n",
      "Epoch:2500, Cost:30.513191773942673\n",
      "Epoch:2550, Cost:30.33679872938792\n",
      "Epoch:2600, Cost:30.165289319180904\n",
      "Epoch:2650, Cost:29.998431440006392\n",
      "Epoch:2700, Cost:29.83600833301756\n",
      "Epoch:2750, Cost:29.677817304355163\n",
      "Epoch:2800, Cost:29.523668573382935\n",
      "Epoch:2850, Cost:29.373384233868588\n",
      "Epoch:2900, Cost:29.22679731527433\n",
      "Epoch:2950, Cost:29.083750932972627\n",
      "Epoch:3000, Cost:28.944097517618843\n",
      "Epoch:3050, Cost:28.807698115128364\n",
      "Epoch:3100, Cost:28.67442174975298\n",
      "Epoch:3150, Cost:28.544144843656678\n",
      "Epoch:3200, Cost:28.41675068717221\n",
      "Epoch:3250, Cost:28.292128954601658\n",
      "Epoch:3300, Cost:28.170175261013394\n",
      "Epoch:3350, Cost:28.050790756003273\n",
      "Epoch:3400, Cost:27.933881750839003\n",
      "Epoch:3450, Cost:27.81935937579952\n",
      "Epoch:3500, Cost:27.707139264867113\n",
      "Epoch:3550, Cost:27.597141265234725\n",
      "Epoch:3600, Cost:27.489289169356653\n",
      "Epoch:3650, Cost:27.38351046750899\n",
      "Epoch:3700, Cost:27.279736119033334\n",
      "Epoch:3750, Cost:27.17790034062251\n",
      "Epoch:3800, Cost:27.077940410171053\n",
      "Epoch:3850, Cost:26.979796484858976\n",
      "Epoch:3900, Cost:26.883411432266055\n",
      "Epoch:3950, Cost:26.78873067343044\n",
      "Epoch:4000, Cost:26.695702036867715\n",
      "Epoch:4050, Cost:26.604275622658772\n",
      "Epoch:4100, Cost:26.514403675798043\n",
      "Epoch:4150, Cost:26.426040468066283\n",
      "Epoch:4200, Cost:26.339142187759986\n",
      "Epoch:4250, Cost:26.25366683666771\n",
      "Epoch:4300, Cost:26.169574133739047\n",
      "Epoch:4350, Cost:26.086825424938514\n",
      "Epoch:4400, Cost:26.005383598821727\n",
      "Epoch:4450, Cost:25.925213007410186\n",
      "Epoch:4500, Cost:25.84627939197683\n",
      "Epoch:4550, Cost:25.76854981338629\n",
      "Epoch:4600, Cost:25.69199258666441\n",
      "Epoch:4650, Cost:25.61657721949685\n",
      "Epoch:4700, Cost:25.542274354381366\n",
      "Epoch:4750, Cost:25.469055714180445\n",
      "Epoch:4800, Cost:25.396894050841308\n",
      "Epoch:4850, Cost:25.32576309706703\n",
      "Epoch:4900, Cost:25.255637520741402\n",
      "Epoch:4950, Cost:25.186492881923765\n",
      "[-0.53523139 -0.58499521 -0.52556189 -0.54050373 -0.19832743 -0.07444304\n",
      " -0.54178976 -0.60548611 -0.11022325  0.39219797 -0.59428922  0.13754051\n",
      " -0.44486802 -0.57419536 -0.13523464  0.37073911  0.04514949 -0.08435191\n",
      "  0.17858416  0.43370015 -0.70625411 -0.77249647 -0.64466902 -0.65646715\n",
      " -0.63594453 -0.22941161 -0.58396114 -0.70080155 -0.62811938 -0.12542917\n",
      "  0.35014172]\n"
     ]
    }
   ],
   "source": [
    "m,cost_array = fit(X_train_scaled,Y_train,5000,0.01)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost_array)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = predict(X_train_scaled,m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.59154929577466"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(Y_train,y_pred_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = np.append(X_val_scaled,np.ones(X_val_scaled.shape[0]).reshape(-1,1),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = predict(X_val_scaled,m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.9020979020979"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(Y_val,y_pred_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
