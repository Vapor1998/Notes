{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To move our original feature dataset, into a higher dimensional dataset, what we will do is we will choose a landmark points, \n",
    "and to convert a x, lets say we have an x in original dimension, to move this x into higher dimension, feature $f_{i}$, is going to be a similarity between x and $l_{i}$.  \n",
    "So thats how we will find all new features.  \n",
    "So the way we are chosing our landmark points is that we will make each of our data point as a landmark.  \n",
    "SO if we have data as m*n, this means originally, each of our x was $R^n$ so we have n real numbers presenting our $x_{i}$ what we will do is we will move it to $x_{i}'$ which is going to be $R^m$.  that is similarity of $x_{i}'$  with all m (training)datapoints.  \n",
    "Thats how we are going to get to the higher dimension.  \n",
    "We are assuming m > n. That means we have more training datapoints than number of features.  \n",
    "We will not ne changing kernel if m > n is not true.  \n",
    "How are we going to choose our similarity function?  \n",
    "SO what are the options of similarity functions?  \n",
    "So we find the similarity function that is $sim(x, l_{i})$, we have many options for this.  \n",
    "First option we will see is \n",
    "1. ##### Linear Kernel.  \n",
    "    It states that we are going to stay in the same dimensionality.  \n",
    "    We are not going to move to other dimension.  \n",
    "    So if we are in $R^n$, we stay in $R^n$ and we dont move in $R^m$.  \n",
    "    The parameters we will be finding we call it as $\\theta$ will basically be dependent upon the original features \n",
    "    and not the new features $\\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} .... + \\theta_{n}x_{n}$.  \n",
    "    We can use this in 2 cases, when m < n. In this case we dont want to move to new dimension as new dimension will be  lesser     than tthe current dimension.  Another case where m is Huge.Lets say the m is 100000, in this case if we want to move to new     dimension, there will be too much feature and the running time of Algorithm will decrease. \n",
    "    The following kernel will be prefered for quick results if we originally have 40,000 data-points and 1000 features is the       Linear Kernel because Linear Kernel is the fastest among others mentioned here and considering the amount of data we have.\n",
    "    we have a dataset of m data-points and n features where m>n ( we have sufficiently more data-points than the features ).         Number of new features after performing the operations of linear kernel will be n as Linear kernel does not affect our           features and keep them exactly same.\n",
    "\n",
    "    \n",
    "2. ###### Gaussian Kernel  \n",
    "    It says simlarity between $$sim(x, l_{i}) = e^{\\frac{-||x - l_{i}|| ^ 2}{2\\sigma^2}}$$ where $\\sigma$ is the parameter that     we can control. If $x$ = $l_{i}$, this means similarity between them is 1. So above equation becomes $e^0$ which is 1.  \n",
    "    So lets say $x$ and $li$ is very far which means numerator is very huge and equation becomes $e^{hugenumber} \\approx 0$.  \n",
    "    SO gaussian Kernel gives us values between 0 and 1.  \n",
    "    1 means they are same and 0 means they are very far away from each other.  \n",
    "    Lets say m is 50000, so we use this kernel as it does not satisfy the above two conditions of the linear kernel. \n",
    "    We call this kernel as RBF kernel as well.  \n",
    "    It mean when ‘1’ is returned as a value from the similarity function while using Gaussian Kernel because The points being       considered are exactly similar. The term on the power of e becomes 0 when two exactly same points are compared and hence         results in 1.\n",
    "\n",
    "\n",
    "3. ###### Polynomial Kernel.  \n",
    "    It is equal to $$poly(x, l_{i}) = (x^Tl_{i} + a)^b$$ where a is some constant. We can choose a and b.  \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
