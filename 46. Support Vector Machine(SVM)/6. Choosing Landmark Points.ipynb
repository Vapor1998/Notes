{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we move from one dimension to other dimension?.\n",
    "In SVM what we do is lets say our data is m*n, this means we have m datapoints and each has n features.  \n",
    "In case of SVM we will make all these m training data points to be our landmark points.  \n",
    "SO if we have x, it will be in $R^n$ , We will find similarity of x in each datapoints, that will give us a vector where 0th data will have similarity with x, 1st data with x ... m - 1 data with x.  So basically we have $R^n$ features, we are moving it to $R^m$ features where m is no of rows.  \n",
    "SO new features will have m datapoints, but each will have m features as well.  \n",
    "So we are moving to m features for each datapoints that happens for testing as well as training data.  \n",
    "The training datapoints are considered to be as landmarks.  \n",
    "We will be using them as landmarks.  \n",
    "\n",
    "If there are n data points and m features then what will be the total number of features after choosing the landmarks is n.  \n",
    "  \n",
    "  \n",
    "  \n",
    "After selecting landmark points, all left to do in the SVM algorithm is very similar to KNN( K Nearest Neighbours ) is False because unlike in KNN, in SVM how much far away is a data point from a landmark also matters.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
