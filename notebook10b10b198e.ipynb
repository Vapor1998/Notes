{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras.models import Sequential\nimport tensorflow as tf\nfrom keras.layers import Dense\nimport tensorflow.compat.v1 as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\nfrom keras.layers import Dense, Conv2D, Flatten, Dropout,BatchNormalization,MaxPooling2D\n","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:51:03.287197Z","iopub.execute_input":"2021-09-02T14:51:03.287454Z","iopub.status.idle":"2021-09-02T14:51:07.763923Z","shell.execute_reply.started":"2021-09-02T14:51:03.287424Z","shell.execute_reply":"2021-09-02T14:51:07.763032Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import csv\n\ndata = {}\nwith open('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv') as f:\n    reader = csv.reader(f)\n    \n    # first row in csv has column headers, we dont want column headers. \n    next(reader)\n    \n    # now getting our key-value pair\n    for row in reader:\n        key = row[1]\n        if key in data:\n            data[key].append(row[2])\n        else:\n            data[key] = [row[2]]","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:52:08.851212Z","iopub.execute_input":"2021-09-02T14:52:08.851540Z","iopub.status.idle":"2021-09-02T14:52:08.889395Z","shell.execute_reply.started":"2021-09-02T14:52:08.851511Z","shell.execute_reply":"2021-09-02T14:52:08.888582Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data.keys()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:52:12.582760Z","iopub.execute_input":"2021-09-02T14:52:12.583099Z","iopub.status.idle":"2021-09-02T14:52:12.591396Z","shell.execute_reply.started":"2021-09-02T14:52:12.583069Z","shell.execute_reply":"2021-09-02T14:52:12.590210Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"dict_keys(['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])"},"metadata":{}}]},{"cell_type":"code","source":"distraction_list = list(data.keys())","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:52:16.963015Z","iopub.execute_input":"2021-09-02T14:52:16.963330Z","iopub.status.idle":"2021-09-02T14:52:16.969073Z","shell.execute_reply.started":"2021-09-02T14:52:16.963302Z","shell.execute_reply":"2021-09-02T14:52:16.968310Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# so we need to make master_data directory.\n# inside it, we create two subdirectories training and testing.\n\nimport os\nos.mkdir('master_data')\nos.mkdir('master_data/training')\nos.mkdir('master_data/testing')\nos.mkdir('master_data/validation')\n","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:52:19.307242Z","iopub.execute_input":"2021-09-02T14:52:19.307565Z","iopub.status.idle":"2021-09-02T14:52:19.312376Z","shell.execute_reply.started":"2021-09-02T14:52:19.307534Z","shell.execute_reply":"2021-09-02T14:52:19.311347Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# inside the training and testing, we need to make 10 new subdirectories related to these distractions.\n# so we iterate over each distractions.\nfor distraction in distraction_list:\n    os.mkdir(os.path.join('master_data/training/', distraction))\n    os.mkdir(os.path.join('master_data/testing/', distraction))\n    os.mkdir(os.path.join('master_data/validation/', distraction))\n\n# we have created subdirectiories inside training and testing but the directories are empty so we need to fill them\n# with source directory images.","metadata":{"execution":{"iopub.status.busy":"2021-09-02T14:52:22.037510Z","iopub.execute_input":"2021-09-02T14:52:22.037863Z","iopub.status.idle":"2021-09-02T14:52:22.044276Z","shell.execute_reply.started":"2021-09-02T14:52:22.037830Z","shell.execute_reply":"2021-09-02T14:52:22.043279Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import shutil as sh\nsplit_size = 0.7\nval_size  = 0.1\n\nfor dis, images in data.items():\n    train_size = int(split_size*len(images))\n    val_size = int(val_size*len(images))\n    train_images = images[:train_size]\n    val_images = images[train_size:val_size]\n    test_images = images[train_size + val_size:]\n    for image in train_images:\n        source = os.path.join('../input/state-farm-distracted-driver-detection/imgs/train',  dis,image)\n        dest = os.path.join('master_data/training',   dis)\n        sh.copy(source, dest)\n    for image in test_images:\n        source = os.path.join('../input/state-farm-distracted-driver-detection/imgs/train', dis, image)\n        dest = os.path.join('master_data/testing',  dis)\n        sh.copy(source, dest)\n        \n    for image in val_images:\n        source = os.path.join('../input/state-farm-distracted-driver-detection/imgs/train', dis, image)\n        dest = os.path.join('master_data/validation',  dis)\n        sh.copy(source, dest)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-09-02T14:52:27.176699Z","iopub.execute_input":"2021-09-02T14:52:27.177143Z","iopub.status.idle":"2021-09-02T14:54:47.612165Z","shell.execute_reply.started":"2021-09-02T14:52:27.177102Z","shell.execute_reply":"2021-09-02T14:54:47.611056Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_dir = 'master_data/training'\ntest_dir = 'master_data/testing'\nval_dir = 'master_data/validation'\n\n\ntrain_datagen = ImageDataGenerator(rescale = 1.0/255)\ntrain_generator = train_datagen.flow_from_directory(\n                                train_dir,   # directory from which we want to generate our data.\n                                target_size = (100, 100),  # telling what is the size of the class\n                                class_mode =  'categorical',  # we need to tell what is the mode of classification, eg 'binary' \n                                batch_size = 128\n)\n\ntest_datagen = ImageDataGenerator(rescale = 1.0/255)\ntest_generator = test_datagen.flow_from_directory(\n                                test_dir,   # directory from which we want to generate our data.\n                                target_size = (100, 100),  # telling what is the size of the class\n                                class_mode =  'categorical',  # we need to tell what is the mode of classification, eg 'binary' \n                                batch_size = 128\n)\n\nval_datagen = ImageDataGenerator(rescale = 1.0/255)\nval_generator = val_datagen.flow_from_directory(\n                                val_dir,   # directory from which we want to generate our data.\n                                target_size = (100, 100),  # telling what is the size of the class\n                                class_mode =  'categorical',  # we need to tell what is the mode of classification, eg 'binary' \n                                batch_size = 128\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:00:12.792431Z","iopub.execute_input":"2021-09-02T15:00:12.792780Z","iopub.status.idle":"2021-09-02T15:00:14.020519Z","shell.execute_reply.started":"2021-09-02T15:00:12.792747Z","shell.execute_reply":"2021-09-02T15:00:14.019553Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Found 15692 images belonging to 10 classes.\nFound 499 images belonging to 10 classes.\nFound 5985 images belonging to 10 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"es = EarlyStopping(monitor = 'loss', patience = 2, min_delta=0.01)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:00:23.210261Z","iopub.execute_input":"2021-09-02T15:00:23.210596Z","iopub.status.idle":"2021-09-02T15:00:23.215873Z","shell.execute_reply.started":"2021-09-02T15:00:23.210566Z","shell.execute_reply":"2021-09-02T15:00:23.214948Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    # layer 1\n    Conv2D(16, (3,3), activation = 'relu', input_shape = (64, 64, 1)),\n    BatchNormalization(),\n    Conv2D(32,(3,3), activation = 'relu', padding = 'same'), \n    BatchNormalization(axis = 3),\n    MaxPooling2D(pool_size = (2,2), padding = 'same'),\n    Dropout(0.3),\n    \n    # layer 2\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    BatchNormalization(),\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'), \n    BatchNormalization(axis = 3),\n    MaxPooling2D(pool_size = (2,2), padding = 'same'),\n    Dropout(0.3),\n    \n    #layer 3\n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n    BatchNormalization(),\n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'), \n    BatchNormalization(axis = 3),\n    MaxPooling2D(pool_size = (2,2), padding = 'same'),\n    Dropout(0.5),\n    \n    # output\n    Flatten(),\n    Dense(512, activation ='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(128, activation = 'relu'),\n    Dropout(0.25),\n    \n    # Last Layer is Important coz we have to decide here mow many classes are there in the images\n    Dense(10, activation ='softmax')\n\n\n    \n])\n\nmodel.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:07:05.116406Z","iopub.execute_input":"2021-09-02T15:07:05.116806Z","iopub.status.idle":"2021-09-02T15:07:05.314240Z","shell.execute_reply.started":"2021-09-02T15:07:05.116769Z","shell.execute_reply":"2021-09-02T15:07:05.313345Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_6 (Conv2D)            (None, 62, 62, 16)        160       \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 62, 62, 16)        64        \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 62, 62, 32)        4640      \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 62, 62, 32)        128       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 31, 31, 32)        0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 31, 31, 32)        0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 31, 31, 64)        18496     \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 31, 31, 64)        256       \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 31, 31, 64)        36928     \n_________________________________________________________________\nbatch_normalization_10 (Batc (None, 31, 31, 64)        256       \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 16, 16, 64)        0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 16, 16, 128)       73856     \n_________________________________________________________________\nbatch_normalization_11 (Batc (None, 16, 16, 128)       512       \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 16, 16, 128)       147584    \n_________________________________________________________________\nbatch_normalization_12 (Batc (None, 16, 16, 128)       512       \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 8, 8, 128)         0         \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 8, 8, 128)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 8192)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 512)               4194816   \n_________________________________________________________________\nbatch_normalization_13 (Batc (None, 512)               2048      \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 128)               65664     \n_________________________________________________________________\ndropout_9 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 4,547,210\nTrainable params: 4,545,322\nNon-trainable params: 1,888\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(train_generator, epochs = 10, verbose = 1, validation_data = val_generator , callbacks = [es])","metadata":{"execution":{"iopub.status.busy":"2021-09-02T15:07:41.810923Z","iopub.execute_input":"2021-09-02T15:07:41.811247Z","iopub.status.idle":"2021-09-02T15:07:42.940624Z","shell.execute_reply.started":"2021-09-02T15:07:41.811218Z","shell.execute_reply":"2021-09-02T15:07:42.938865Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-4436f5fe606d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m:  No algorithm worked!\n\t [[node sequential_1/conv2d_6/Conv2D (defined at <ipython-input-21-174bcdc9750c>:1) ]] [Op:__inference_train_function_5745]\n\nFunction call stack:\ntrain_function\n"],"ename":"NotFoundError","evalue":" No algorithm worked!\n\t [[node sequential_1/conv2d_6/Conv2D (defined at <ipython-input-21-174bcdc9750c>:1) ]] [Op:__inference_train_function_5745]\n\nFunction call stack:\ntrain_function\n","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}