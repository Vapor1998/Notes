{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA on Breast Cancer Dataset**  \n",
    "We will first Run Logistic Regression on breast cancer dataset, look at the accuracy, time.  \n",
    "And then we will apply PCA to reduce dimensionality and then we will apply Logistic Regression and then compare the accuracy and time taken on both cases.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition, ensemble, datasets, linear_model\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = breast_cancer.data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_std = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_std, breast_cancer.target, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply PCA only on training data.  \n",
    "And we will use same PCA object for applying PCA on testing data as well.  \n",
    "We should not use PCA on applying test data because test data are not used in training.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components = 15)\n",
    "## we have 30 features so lets try to make it 15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pca = pca.fit_transform(x_train)  ## transforming train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_pca = pca.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will call only transform and this will use exact same component so in the first call(fit transform) it will\n",
    "do a lot more work it will find those components and this one(transform) it will just going to move the testing data to \n",
    "those component.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is without PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "lr.fit(x_train, y_train)\n",
    "print(lr.score(x_test, y_test))\n",
    "## Also we want to see how much time it takes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.016799211502075195\n",
      "Score:  0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "lr.fit(x_train, y_train)\n",
    "ending = time.time()\n",
    "print('Time: ' ,ending - start)\n",
    "print('Score: ', lr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This time we will do the same thing but with the PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.014199972152709961\n",
      "Score:  0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "lr.fit(x_train_pca, y_train)\n",
    "ending = time.time()\n",
    "print('Time: ' ,ending - start)\n",
    "print('Score: ', lr.score(x_test_pca, y_test))\n",
    "\n",
    "\n",
    "## different run will give you different amount of time.\n",
    "## It also depends upon what else is running on CPU.\n",
    "\n",
    "## lets say if we run it 10 - 15 times and take avg of it , pca one will run faster.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is only 15 dimensional data. But if we move to larger dataset, we will find out  \n",
    "PCA is very amazing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.02746837,  5.81556555,  2.85848795,  1.91901713,  1.70021491,\n",
       "        1.20663908,  0.65333715,  0.42673847,  0.42645054,  0.34558986,\n",
       "        0.30805491,  0.25605447,  0.228152  ,  0.14326274,  0.0926283 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_\n",
    "\n",
    "## below means the pca1 is explaining 13.02746837 variance.  \n",
    "## second one is explaining 5.81556555 and so on and we see that it keeps going down.  \n",
    "## so the maximum information that we are getting is through first few components.  \n",
    "## These are the Eigen Values and the components_ that we saw above is Eigen Vectors.  \n",
    "\n",
    "## Eigen Values are very Important and it tells us which vector is important.  \n",
    "## Using this values we can fix which value to pick and which vector to pick.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
