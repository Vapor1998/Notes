{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF-T-YCPBpaN"
   },
   "source": [
    "#**TensorFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fs9RlcetCZqW"
   },
   "source": [
    "**What will you learn?**\n",
    "1. **Installing TensorFlow**\n",
    "2. **TensorFlow Constants**\n",
    "3. **TensorFlow Sessions**\n",
    "4. **TensorFlow Variable**\n",
    "5. **TensorFlow Placeholder**\n",
    "6. **Neural Network using TensorFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rONhqMDoBpfI"
   },
   "source": [
    "TensorFlow is a software library or framework, designed by the Google team to implement machine learning and deep learning concepts in the easiest manner. It combines the computational algebra of optimization techniques for easy calculation of many mathematical expressions.\n",
    "\n",
    "**Important features of TensorFlow**:\n",
    "1. It includes a feature that defines, optimizes and calculates mathematical\n",
    "expressions easily with the help of multi-dimensional arrays called tensors.\n",
    "2. It includes a high scalable feature of computation with various data sets.\n",
    "3. It includes a programming support of deep neural networks and machine learning techniques.\n",
    "4. TensorFlow uses GPU computing, automating management. It also includes a\n",
    "unique feature of optimization of same memory and the data used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlr5hxNPBpik"
   },
   "source": [
    "##**Installing Tensorflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7UG9Qk8BplM"
   },
   "source": [
    "Use pip to install “Tensorflow” in the system. The command used for installation\n",
    "is mentioned as below:\n",
    "$$pip \\;install\\; tensorflow$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDQ8uXf3Bpnv"
   },
   "source": [
    "Now after the installation process, to check if TensorFlow is installed correctly import it into your workspace under the alias tf:\n",
    "\n",
    "$$import \\;\\;tensorflow\\;\\; as\\;tf$$\n",
    "\n",
    "if the command executes properly then it is installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcbaSJpOBpqM"
   },
   "source": [
    "##**Constants**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMdjXA7oBptA"
   },
   "source": [
    "Contants create a node that takes value and it does not change. You can simply create a constant tensor using **tf.constant**. It accepts the five arguments:\n",
    "1. value: A constant value (or list) of output type dtype.\n",
    "2. dtype: The type of the elements of the resulting tensor.\n",
    "3. shape: Optional dimensions of resulting tensor.\n",
    "4. name: Optional name for the tensor.\n",
    "5. verify_shape: Boolean that enables verification of a shape of values.\n",
    "\n",
    "But declaring a constant is only half the job done. To get the value or perform various operations on constants- we use sessions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.constant(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b\n",
    "# it is not printing object value, rather it is printing tensor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=5>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a + b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it is not doing addition, it just saying numpy=5, 5 is what we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we actually want to do addition, we need to create tensorflow session, run it, and pass it what really we want to evaluate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# session  \n",
    "sess = tf.Session()\n",
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# even after running this, if we try and print a, it is going to be a tensor object\n",
    "# if we want value of a, we need to run \n",
    "sess = tf.compat.v1.Session()\n",
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so if we want the value of a, \n",
    "aval = sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aval\n",
    "# now aval is python object which has the value a has. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants can not just be integers, it can be this as well.  \n",
    "a1 = tf.constant([[3,3]]) # 1x2\n",
    "a2 = tf.constant([[3], [3]]) #2x1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To multiply matrix, tensorflow has function matmul()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul:0' shape=(1, 1) dtype=int32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(a1, a2)\n",
    "# it has not done the calculation yet, it is telling us what is the shape going to be like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ofcourse we need to pass session in order to multiply matrix.\n",
    "sess.run(tf.matmul(a1, a2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once assigned, we cannot change the constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ou6gM14sBpv-"
   },
   "source": [
    "##**Sessions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqfCPcA5JhKt"
   },
   "source": [
    "A session is basically the backbone of a tensorflow program. A session fires up the program to get the constants ready and perform the desired operation.\n",
    "We define a session sess by using tf.Session() function. This fires up our program and we are ready to calculate and display the result. We do that by using session.run(result) function inside the print() function.\n",
    "\n",
    "Lastly, we close the session by using sess.close() function.  \n",
    "Once we close the session, the operations we did inside that session, we need to do that again.  \n",
    "    \n",
    "According to TF 1:1 Symbols Map, in TF 2.0 you should use **tf.compat.v1.Session() instead of tf.Session()**  \n",
    "  \n",
    "https://docs.google.com/spreadsheets/d/1FLFJLzg7WNP6JHODX5q8BDgptKafq_slHpnHVbJIteQ/edit#gid=0  \n",
    "  \n",
    "To get TF 1.x like behaviour in TF 2.0 one can run   \n",
    "  \n",
    "import tensorflow.compat.v1 as tf  \n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to create the session object is like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "c = a + b\n",
    "sess = tf.compat.v1.Session()\n",
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the following lines of code to start up an interactive Session, run the result and close the Session automatically again after printing the output. Using eval() function inside the session will print the result for you. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "#session\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "c = a + b\n",
    "\n",
    "# other way to create session is like this. \n",
    "# Everything we need to do with this session object is we need to write it inside this 'with' statement.\n",
    "with tf.compat.v1.Session() as sess: \n",
    "    print(sess.run(c))\n",
    "    print(c.eval())  # not using session object. We cant use eval() outside 'with' block because sess is default inside 'with'\n",
    "                     # block while there is no default session object outside 'with' block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3211,
     "status": "ok",
     "timestamp": 1611601290891,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "mGOP0fP1QUm9",
    "outputId": "efb74e76-4e9c-43ad-b006-ae3962425503"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 7131,
     "status": "ok",
     "timestamp": 1611601301659,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "nsN6VjHZKr_G"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf #version1 of tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1741,
     "status": "ok",
     "timestamp": 1611601301664,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "JJSodC5YQMMf",
    "outputId": "a8e11655-86cb-4ce8-d550-e214501681d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1675,
     "status": "ok",
     "timestamp": 1611601303296,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "wl2btbYfJgKv"
   },
   "outputs": [],
   "source": [
    "a = tf.constant(6) #creating constants\n",
    "b = tf.constant(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2435,
     "status": "ok",
     "timestamp": 1611601305022,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "V5V494g9J9es",
    "outputId": "424b9ed7-c7b4-4d45-b09c-85380b52f128"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2419,
     "status": "ok",
     "timestamp": 1611601308375,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "7JH011ByJ-Vv"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2785,
     "status": "ok",
     "timestamp": 1611601311902,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "0OQ3IGAhLtNS",
    "outputId": "62a2ff3e-502e-48bb-a8be-c6a4b5443874"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3664,
     "status": "ok",
     "timestamp": 1611601315755,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "_UZ5IjCdQ9yD",
    "outputId": "025dd3ed-928f-48a7-8ab7-18c59fc07f6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18, 15]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constants can be 2D matrices, strings etc.\n",
    "a1 = tf.constant([[3,3]])\n",
    "a2 = tf.constant([[3,2],[3,3]])\n",
    "res = tf.matmul(a1, a2)\n",
    "sess.run(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1687,
     "status": "ok",
     "timestamp": 1611601317368,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "rcUCP0a7RIT-",
    "outputId": "e2dbf0e2-6781-4224-9dac-930a9101d1f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=tf.constant(8)\n",
    "a=tf.constant(28) # is perfectly valid as a new tensor object is created here \n",
    "\n",
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTkvYSlkSJW6"
   },
   "source": [
    "You can also use the following lines of code to start up an interactive Session, run the result and close the Session automatically again after printing the output. Using eval() function inside the session will print the result for you. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2176,
     "status": "ok",
     "timestamp": 1611601321713,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "3GgfUDGFRLXx",
    "outputId": "70cdf40a-014a-4e50-ffbe-4c8c1fe67837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#session\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "c = a + b\n",
    "with tf.Session() as sess: \n",
    "  print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c4bM9hIYqOR"
   },
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRhlsHMWYqSW"
   },
   "source": [
    "##**Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVKs9eagY4CR"
   },
   "source": [
    "TensorFlow has Variable nodes too which can hold variable data. They are mainly used to hold and update parameters of a training model.\n",
    "\n",
    "Variables are in-memory buffers containing tensors. They must be explicitly initialized and can be saved to disk during and after training. You can later restore saved values to exercise or analyze the model.\n",
    "\n",
    "An important difference to note between a constant and Variable is:\n",
    "\n",
    "A constant’s value is stored in the graph and its value is replicated wherever the graph is loaded. A variable is stored separately, and may live on a parameter server.  \n",
    "We cant change the constants once we defined it, but we can change the variables.  \n",
    "By default, variables are global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables \n",
    "var1 = tf.Variable(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32_ref>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_1:0' shape=(1,) dtype=int32_ref>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1 = tf.Variable([100])\n",
    "var1\n",
    "# variable with shape (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_2:0' shape=(1, 1) dtype=int32_ref>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1 = tf.Variable([[100]])\n",
    "var1\n",
    "# variable with shape (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value Variable_5\n\t [[node Variable_5/read (defined at <ipython-input-29-13e33aae8090>:1) ]]\n\nOriginal stack trace for 'Variable_5/read':\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n    result = self._run_cell(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n    return runner(coro)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-13e33aae8090>\", line 1, in <module>\n    var1 = tf.Variable(100)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 266, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 212, in _variable_v1_call\n    return previous_getter(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 205, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2628, in default_variable_creator\n    return variables.RefVariable(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 270, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1658, in __init__\n    self._init_from_args(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1863, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 289, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3944, in identity\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3561, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1360\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1450\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1451\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_5\n\t [[{{node Variable_5/read}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-13e33aae8090>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1190\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1192\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1369\u001b[0m                            run_metadata)\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1392\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1394\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_5\n\t [[node Variable_5/read (defined at <ipython-input-29-13e33aae8090>:1) ]]\n\nOriginal stack trace for 'Variable_5/read':\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n    result = self._run_cell(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n    return runner(coro)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-13e33aae8090>\", line 1, in <module>\n    var1 = tf.Variable(100)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 266, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 212, in _variable_v1_call\n    return previous_getter(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 205, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2628, in default_variable_creator\n    return variables.RefVariable(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 270, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1658, in __init__\n    self._init_from_args(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1863, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 289, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3944, in identity\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3561, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
     ]
    }
   ],
   "source": [
    "var1 = tf.Variable(100)\n",
    "var2 = tf.Variable(3)\n",
    "\n",
    "# now we adding two variables\n",
    "sums = tf.add(var1, var2)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(sums)\n",
    "\n",
    "# the issue with variables in tf is you need to explicitly call initialize on ypur variables and only then \n",
    "# these variables will get 100 and 3.  \n",
    "# If we run right now, it will get error saying uninitialized variables.  \n",
    "# You need to explicitly initialize the variables.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we need to do is in the same session, we need to pass a command **tf.global_variables_initializer()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1 = tf.Variable(100)\n",
    "var2 = tf.Variable(3)\n",
    "\n",
    "# these are global variables we have created.\n",
    "# now we adding two variables\n",
    "sums = tf.add(var1, var2)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value Variable_10\n\t [[node Variable_10/read (defined at <ipython-input-31-5ee650c86354>:2) ]]\n\nOriginal stack trace for 'Variable_10/read':\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n    result = self._run_cell(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n    return runner(coro)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-31-5ee650c86354>\", line 2, in <module>\n    var2 = tf.Variable(3)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 266, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 212, in _variable_v1_call\n    return previous_getter(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 205, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2628, in default_variable_creator\n    return variables.RefVariable(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 270, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1658, in __init__\n    self._init_from_args(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1863, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 289, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3944, in identity\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3561, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1360\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1450\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1451\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_10\n\t [[{{node Variable_10/read}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-5ee650c86354>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msess1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0msess1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1190\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1192\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1369\u001b[0m                            run_metadata)\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1392\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1394\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_10\n\t [[node Variable_10/read (defined at <ipython-input-31-5ee650c86354>:2) ]]\n\nOriginal stack trace for 'Variable_10/read':\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n    result = self._run_cell(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n    return runner(coro)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-31-5ee650c86354>\", line 2, in <module>\n    var2 = tf.Variable(3)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 266, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 212, in _variable_v1_call\n    return previous_getter(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 205, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2628, in default_variable_creator\n    return variables.RefVariable(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 270, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1658, in __init__\n    self._init_from_args(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1863, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 289, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3944, in identity\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3561, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
     ]
    }
   ],
   "source": [
    "var1 = tf.Variable(100)\n",
    "var2 = tf.Variable(3)\n",
    "\n",
    "# now we adding two variables\n",
    "sums = tf.add(var1, var2)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess1 = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess1.run(sums)\n",
    "\n",
    "# lets say if we create another session and pass the sum on its run without passing tf.global_variables_initializer(), \n",
    "# it will give the same error because we are trying to find the sum in other session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we want to create local variables, we can pass scope to it.  \n",
    "# if we want to change the value of variable, \n",
    "\n",
    "var1.assign(1232)\n",
    "# it will not really change the value of variable, it is an assignment object which we have not runned using session \n",
    "# so it will not change anything.  \n",
    "\n",
    "sess.run(var1)\n",
    "# this is still same because we have not run the assign on sess object yet.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1232"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(var1.assign(1232))\n",
    "sess.run(var1)\n",
    "# as we can see, var1 value has been changed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after assigning, if we run the sums, it will be different\n",
    "sess.run(sums)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "executionInfo": {
     "elapsed": 5021,
     "status": "error",
     "timestamp": 1611601334017,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "ULhKAslnZOZN",
    "outputId": "b1bc58cc-967c-4d14-b495-05794375208c"
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable\n\t [[{{node _retval_Variable_0_0}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-caac501a35ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvar1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# generates an error because a variable is supposed to be explicitly intialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable\n\t [[{{node _retval_Variable_0_0}}]]"
     ]
    }
   ],
   "source": [
    "var1= tf.Variable(100)\n",
    "sess = tf.Session()\n",
    "sess.run(var1) # Generates an error because a variable is supposed to be explicitly intialized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1050,
     "status": "ok",
     "timestamp": 1611601338488,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "oZBkpI5WZazE",
    "outputId": "6f3422b4-99df-4b7c-b741-aedbf5c8665a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer()) # initializing global variable var1 now\n",
    "temp=var1.assign(122)  #assign will assign values to variable\n",
    "sess.run(var1)  #var1 containes old value because assign is not run yet in session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1013,
     "status": "ok",
     "timestamp": 1611601346269,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "EWLOXSnSZxsW",
    "outputId": "c8111947-c1b8-491b-86a7-376a01e3778b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(temp) # now var1 has new value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1212,
     "status": "ok",
     "timestamp": 1611601346659,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "OkukKSa6aH69",
    "outputId": "ea8f6499-cf6f-4d87-8249-1bcf63b969fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1 = tf.Variable(100)\n",
    "var2 = tf.Variable(200)\n",
    "var3 = tf.Variable(300) \n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(var3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4s-X0SXFY3-9"
   },
   "source": [
    "##**Placeholders**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tOprFjUY38A"
   },
   "source": [
    "Placeholders are more basic than a variable. It is simply a variable that we asign data in a future time.\n",
    "\n",
    " Placeholders are nodes whose value is fed in at execution time. Placeholders don't need any initial value; only a datatype (such as float32) and a tensor shape\n",
    "\n",
    "While evaluating the graph involving placeholder nodes, a feed_dict parameter is passed to the session’s run method to specify Tensors that provide concrete values to these placeholders.    \n",
    "\n",
    "---------------\n",
    "Lets say x = tf.variable(5) y = x* 2,  \n",
    "It will not do any work unless we pass it on the run(y) and before that we need to explicit declare the variable.  \n",
    "So there is no work before calling run(). \n",
    "So placeholder is the way , lets say x = tf.placeholder(). So it means we dont know what the value of x is.  \n",
    "So now if we call y on the run(), it will give error because we havent give the value of x.  \n",
    "So we have to pass the value of x inside run() with y.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder' with dtype int16\n\t [[node Placeholder (defined at <ipython-input-37-6c94cc6d1fd3>:1) ]]\n\nOriginal stack trace for 'Placeholder':\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n    result = self._run_cell(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n    return runner(coro)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-6c94cc6d1fd3>\", line 1, in <module>\n    x = tf.placeholder(tf.int16)  # inside we write what type of data we want to store.\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 3285, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 6727, in placeholder\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3561, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1360\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1450\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1451\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype int16\n\t [[{{node Placeholder}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-6c94cc6d1fd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# inside we write what type of data we want to store.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1190\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1192\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1369\u001b[0m                            run_metadata)\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1392\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1394\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype int16\n\t [[node Placeholder (defined at <ipython-input-37-6c94cc6d1fd3>:1) ]]\n\nOriginal stack trace for 'Placeholder':\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n    result = self._run_cell(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n    return runner(coro)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-6c94cc6d1fd3>\", line 1, in <module>\n    x = tf.placeholder(tf.int16)  # inside we write what type of data we want to store.\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 3285, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 6727, in placeholder\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3561, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.int16)  # inside we write what type of data we want to store. \n",
    "sess.run(x)\n",
    "\n",
    "# it gives error saying InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype int16.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so lets pass the value of y inside y of placeholder\n",
    "y = tf.constant(6)\n",
    "sess.run(y)\n",
    "\n",
    "# it will run fine because it is independent of x.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input 'y' of 'Mul' Op has type int32 that does not match type int16 of argument 'x'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1377\u001b[0m             \u001b[0mr_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__r%s__\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1378\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1379\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[1;34m(y, x)\u001b[0m\n\u001b[0;32m   1398\u001b[0m       \u001b[1;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1400\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmaybe_promote_tensors\u001b[1;34m(force_same_dtype, *tensors)\u001b[0m\n\u001b[0;32m   1334\u001b[0m       promoted_tensors.append(\n\u001b[1;32m-> 1335\u001b[1;33m           ops.convert_to_tensor(tensor, dtype, name=\"x\"))\n\u001b[0m\u001b[0;32m   1336\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpromoted_tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1533\u001b[1;33m       raise ValueError(\n\u001b[0m\u001b[0;32m   1534\u001b[0m           \u001b[1;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor conversion requested dtype int32 for Tensor with dtype int16: <tf.Tensor 'Placeholder:0' shape=<unknown> dtype=int16>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-95ffa4c91659>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# lets say if y was dependent of x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1381\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1708\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1709\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1710\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    528\u001b[0m   \"\"\"\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6242\u001b[0m       \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6243\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6244\u001b[1;33m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[0;32m   6245\u001b[0m         \"Mul\", x=x, y=y, name=name)\n\u001b[0;32m   6246\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    553\u001b[0m                   \u001b[0minferred_from\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Default in OpDef\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             raise TypeError(\n\u001b[0m\u001b[0;32m    556\u001b[0m                 \u001b[1;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m                 (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n",
      "\u001b[1;31mTypeError\u001b[0m: Input 'y' of 'Mul' Op has type int32 that does not match type int16 of argument 'x'."
     ]
    }
   ],
   "source": [
    "# lets say if y was dependent of x \n",
    "y = x * tf.constant(6)\n",
    "sess.run(y)  \n",
    "\n",
    "# it gives error because to calculate value of y, we need to calculate value of x which is a placeholder that we are supposed \n",
    "# to pass\n",
    "# T pass value of placeholder, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to pass placeholder value, we need to pass feed_dicy{placeholder:value}\n",
    "x = tf.placeholder(tf.int32)\n",
    "y = x * tf.constant(6)\n",
    "sess.run(y, feed_dict={x:10})\n",
    "\n",
    "# now its running fine  .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 12])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one interesting option while creating the placeholder is we can pass the shape to the placeholder.\n",
    "#x = tf.placeholder(tfint32, shape =()) we can define this later on\n",
    "x = tf.placeholder(tf.int32)\n",
    "y = x * tf.constant(6)\n",
    "sess.run(y, feed_dict={x:[1,2]})\n",
    "# we havent specified the shape so it is running fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (2,) for Tensor 'Placeholder_5:0', which has shape '(2, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-d2c67b39adfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1162\u001b[0m           if (not is_tensor_handle_feed and\n\u001b[0;32m   1163\u001b[0m               not subfeed_t.get_shape().is_compatible_with(np_val.shape)):\n\u001b[1;32m-> 1164\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1165\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (2,) for Tensor 'Placeholder_5:0', which has shape '(2, 3)'"
     ]
    }
   ],
   "source": [
    "# but when we specify the shape, it might give error\n",
    "x = tf.placeholder(tf.int32, shape = (2,3))\n",
    "y = x * tf.constant(6)\n",
    "sess.run(y, feed_dict={x:[1,2]})  \n",
    "# it gives error because input must be of 2x3 so we pass it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6, 12, 18],\n",
       "       [24, 30, 36]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.int32)\n",
    "y = x * tf.constant(6)\n",
    "sess.run(y, feed_dict={x:[[1,2,3],[4,5,6]]})\n",
    "\n",
    "# this is if we want some shape restriction, we can provide the restriction.\n",
    "# but if we keep the shape to be none, it will work fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 1015,
     "status": "ok",
     "timestamp": 1611601353244,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "DYiZx2cGdOhi"
   },
   "outputs": [],
   "source": [
    "x =tf.placeholder(tf.int32) #type is supposed to be specified \n",
    "y =tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1379,
     "status": "ok",
     "timestamp": 1611601353956,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "BLahKAk_dQIu"
   },
   "outputs": [],
   "source": [
    "v = 3 * x\n",
    "sess = tf.Session()\n",
    "#sess.run(v)  # error is generated as v is supposed to use values present in x, which are not provided yet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1037,
     "status": "ok",
     "timestamp": 1611601353957,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "cDwEexT5dW4f",
    "outputId": "8cae3faa-6afe-4cbb-d7a8-ab9a05d960a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to pass values we need to provide a dictionary \n",
    "sess.run(v,feed_dict={x:20}) # see it only requires the values which would be required to compute v hence y value was not asked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1611601354387,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "c7Z9_R_cdaxk",
    "outputId": "362e2195-466d-47d3-e98a-8ed5151d4e08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 24],\n",
       "       [48, 60]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can create multidimensional placeholders also \n",
    "x =tf.placeholder(tf.int32,shape=(2,2))\n",
    "y = x * tf.constant(12)\n",
    "sess.run(y, feed_dict={x:[[1,2], [4,5]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRpOtTAhgBCw"
   },
   "source": [
    "##**Neural Networks using TensorFlow**\n",
    "\n",
    "**Dataset Used - MNIST dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwZQ_iFR8FxK"
   },
   "source": [
    "###**Loading the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 1178,
     "status": "ok",
     "timestamp": 1611601512904,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "ywlUWI87gDIF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1443,
     "status": "ok",
     "timestamp": 1611601400030,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "KVmkICMxgKe5",
    "outputId": "41e86f95-5101-4db2-ba0a-3363e1230d89"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist=input_data.read_data_sets(\"MNIST_data/\",one_hot=True) #mnist dataset where the o/p is onehot encoded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above part is not working so we did this.  \n",
    "\n",
    "**To fetch same dataset from sklearn,   \n",
    "######Explanation:  \n",
    "    from sklearn.datasets import fetch_mldata  \n",
    "\tmnist = fetch_mldata('MNIST original', data_home=custom_data_home)  \n",
    "will fetch the MNIST dataset**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# mnist = tf.keras.datasets.mnist\n",
    "import input_data as ids\n",
    "mnist = ids.read_data_sets('MNIST_data/', one_hot = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_Datasets(train=<input_data._DataSet object at 0x00000178AA16A520>, validation=<input_data._DataSet object at 0x00000178AA16A3D0>, test=<input_data._DataSet object at 0x00000178AA16A6D0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images\n",
    "#it has images so we have this array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape\n",
    "\n",
    "# there are 55000 images with shape 784 which is 28x28. \n",
    "# They are flattened images for you. So we have a 2d array where each image is 784 ehich is actually 28x28 image flattened\n",
    "# for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.validation.images.shape\n",
    "# so dataset has around 70000 images.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need the y labels as well\n",
    "mnist.train.labels.shape\n",
    "# and each image will have 10 sized vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we remember Neural Networks, this is a multiclass classification problem.  \n",
    "we are supposed to classify an image into 10 possible outputs.  \n",
    "So our labels are already converted into One-Hot encoded. If it wasnt, we need to convert it So that we can use it in Neural Network.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to plot the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_image = mnist.train.images[1]  # type of the image will be flat as this will be 1d array(row 0 from train data).\n",
    "\n",
    "# lets convert it into numpy array.  \n",
    "first_image = np.array(first_image, dtype ='float')\n",
    "\n",
    "#then reshape it\n",
    "first_image = first_image.reshape((28, 28))\n",
    "\n",
    "# plotting image\n",
    "plt.imshow(first_image)\n",
    "plt.show()\n",
    "\n",
    "# these are the images we need to train classifier with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1330,
     "status": "ok",
     "timestamp": 1611601410208,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "VMahWKc_gMIo",
    "outputId": "dd228cf3-7193-4d93-b038-1f240579fff9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f3ad2933be0>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f3ad2933b70>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f3b2fac5940>)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1611601410209,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "cJnwysiwgQU6",
    "outputId": "584edd06-b5a1-4e8b-d9bb-1536afbf76c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 784), (55000, 10))"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape , mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 1377,
     "status": "ok",
     "timestamp": 1611601518934,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "3n_De2sqgbGJ"
   },
   "outputs": [],
   "source": [
    "image1=mnist.train.images[4119]\n",
    "image1=np.array(image1,float) #converting the image back into 2d\n",
    "image1=image1.reshape((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 1045,
     "status": "ok",
     "timestamp": 1611601523471,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "yQJjAzVHghlL",
    "outputId": "991c0330-01db-4afc-b47b-a78053a411ce"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leeagDIL8Btp"
   },
   "source": [
    "###**Initialising Weights and Biases**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to know how to Build the Neural Networks for this image.   \n",
    "\n",
    "---------------------\n",
    "So our image is 784 sized, so input layer is going to have 784 entries.  \n",
    "Lets say we are going to have 2 hidden layers, and output layer.  \n",
    "How many units we will have in output layer?  \n",
    "We will have 10 units. Why because we have 10 possible outputs.  \n",
    "How many units should we have for hidden layer?  \n",
    "There is no fixed unit but generally we take between 1000-2000 so we take here 256 in both .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.3290550e-01  5.5623847e-01 -9.7986257e-01 ...  1.0422068e-01\n",
      "  -1.7260568e-01 -4.9216419e-02]\n",
      " [ 1.8069572e+00 -1.7203686e+00  5.7476902e-01 ... -1.8535830e+00\n",
      "  -1.0391542e+00  1.4906520e+00]\n",
      " [ 1.1315254e+00 -3.4493613e-01 -1.4306029e+00 ...  4.7333953e-01\n",
      "  -1.8511908e-01  1.0379558e+00]\n",
      " ...\n",
      " [ 1.1447916e+00  1.0867945e+00  3.0481437e-01 ... -3.3566689e-01\n",
      "   8.9732784e-01  1.0375829e+00]\n",
      " [ 7.4834555e-01  9.9069840e-01  1.3378817e-01 ...  6.2377691e-02\n",
      "   2.5462701e+00 -2.1794763e+00]\n",
      " [ 6.8929428e-01  9.7703598e-02  1.2076625e-03 ...  2.5718936e-01\n",
      "   1.4568635e+00  9.9494076e-01]]\n"
     ]
    }
   ],
   "source": [
    "tf.random.normal([1, 2]) # we need to give a shape in the square bracket.It can also create 3d array for us.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "     print(tf.random.normal([784, 256]).eval())\n",
    "        \n",
    "# so it has created 2d random values array for us which has all random values.\n",
    "# it will be used to initialize random weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "n_classes = 10\n",
    "\n",
    "# we will create dictionary of weights which corrosponds to weights and different layer.  \n",
    "weights = {\n",
    "    'h1':tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([ n_hidden_2, n_classes]))\n",
    "}\n",
    "\n",
    "# similarly we will add the biases\n",
    "# it will not be 2d coz it is only 1 in every layer\n",
    "\n",
    "biases = {\n",
    "    'h1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.random_normal([ n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([  n_classes]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1611602242984,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "83FGcw-sgjHt"
   },
   "outputs": [],
   "source": [
    "n_input = 784\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "n_classes = 10\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "db4aMnfW87kn"
   },
   "source": [
    "###**Forward Propogation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we will create a function for Forward Propogation. it will take X, weights, biases.  \n",
    "So we will do matrix multiplication of X and weights.  \n",
    "SO dimension of X is 10000 x 784, weights are 784x256 at first layer, weight is actually a dictionary, for h1 it is of weight 784x256.  \n",
    "So we will do this multiplication and result will be 10000x256 and we will add biases into it.  \n",
    "So for 10000 images, we will have output as 256 for layer 1.  \n",
    "Then we will use this output for layer2 then we will make that output of layer 2 pass through output layer to get our result.  \n",
    "At hidden layer 1, we will use activation function as 'relu'. 'relu' means *max(a, 0)* which means if it isnegative, it will push it to 0.  \n",
    "And h2 layer activation function will also be relu.  \n",
    "And we will be using identity at the output layer means we will not be using any activation function on the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(x, weights, biases):\n",
    "    in_layer1 = tf.add(tf.matmul(x, weights['h1']), biases['h1']) # this will give you what is net input going in h1\n",
    "    out_layer1 = tf.nn.relu(in_layer1)  # it exist in tensorflow.this is the output of layer1\n",
    "    \n",
    "    in_layer2 = tf.add(tf.matmul(out_layer1, weights['h2']), biases['h2'])\n",
    "    out_layer2 = tf.nn.relu(in_layer2)\n",
    "    \n",
    "    output = tf.add(tf.matmul(out_layer2, weights['out']), biases['out'])\n",
    "    return output \n",
    "\n",
    "# we havent done any optimization, we want to predict the output with random weights.  \n",
    "# now we have to figure out how can we optimize our weightsto get good at predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 1019,
     "status": "ok",
     "timestamp": 1611602245803,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "eeK52iUfjGwj"
   },
   "outputs": [],
   "source": [
    "def fwd_prop(x,weights,biases):\n",
    "    layer1=tf.add(tf.matmul(x,weights['h1']),biases['h1'])\n",
    "    layer1=tf.nn.relu(layer1)  #activation \n",
    "    \n",
    "    layer2=tf.add(tf.matmul(layer1,weights['h2']),biases['h2'])\n",
    "    layer2=tf.nn.relu(layer2)\n",
    "    \n",
    "    output=tf.add(tf.matmul(layer2,weights['out']),biases['out'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WVhRxSc9unP"
   },
   "source": [
    "###**Finding Predictions and Accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we try to Optimize the weights, lets find the predictions first.  \n",
    "So we will do the predictions, we will find out how many of the predictions are correct and we will do it for training and testing\n",
    "we can pass weights and biases but how can we pass X?\n",
    "this x, sometimes will be training data sometime will be testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we will have placeholder, this placeholder will have a float value\n",
    "x = tf.placeholder('float', [None, n_input]) # we dont know the no of images as sometime it will be train,and sometime it wil be\n",
    "                                         # test.So we pass None,\n",
    "                                         # but we know no of feaures\n",
    "# so we need another placeholder, which is y, y is integer\n",
    "y = tf.placeholder(tf.int32, [None, n_classes])  # For shape, we dont know how many images so we pass None, and for each image,\n",
    "                                        # our output label will be a 10 size vector so it will be classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # writing code for better understanding again so that we dont get different output again.\n",
    "# # sess = tf.Session()\n",
    "# # sess.run(tf.global_variables_initializer())\n",
    "# # x = tf.placeholder('float', [None, n_input])\n",
    "# # y = tf.placeholder(tf.int32, [None, n_classes]).\n",
    "# pred = forward_propagation(x, weights, biases) \n",
    "# predictions = tf.argmax(pred, 1)  # to get index which has max value, we use argmax.\n",
    "# correct_labels = tf.argmax(y, 1)\n",
    "# predictions_eval = sess.run(predictions, feed_dict={x: mnist.test.images})  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our output will be of size  10000x10.   \n",
    "To find the actual predictions, we need to predict what is the maximum value in the row.  \n",
    "We need to find argmax among the columns. which means for each row, we need to find the argmax. So in this case, we need tofind the axis as 1.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = forward_propagation(x, weights, biases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "predictions = tf.argmax(pred, 1)  # to get index which has max value, we use argmax.\n",
    "correct_labels = tf.argmax(y, 1)\n",
    "correct_predictions = tf.equal(predictions, correct_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating sessions and predicting\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "predictions_eval = sess.run(predictions, feed_dict={x: mnist.test.images})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 4, ..., 9, 4, 0], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it has predicted the predictions.  \n",
    "It is random because we havent optimized our weights.  \n",
    "Lets say along with predictions, we need to see the labels as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 4, ..., 9, 4, 0], dtype=int64),\n",
       " array([7, 2, 1, ..., 4, 5, 6], dtype=int64),\n",
       " array([False, False, False, ..., False, False, False]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see what correct labels are.  \n",
    "# to find correct labels, we need to feed y as well in the dictionary\n",
    "# to find correct predictions, we need to pass it inside the session as well\n",
    "predictions_eval, labels, correct_predictions = sess.run([predictions, correct_labels, correct_predictions], feed_dict = {x:mnist.test.images, y:mnist.test.labels})\n",
    "predictions_eval, labels, correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1290"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wherever predictions is correct it gives true else false. \n",
    "# lets see how many are true.  \n",
    "correct_predictions.sum()\n",
    "\n",
    "# this is for test data, we need to do it for train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 949,
     "status": "ok",
     "timestamp": 1611602247065,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "5fbW_Ygo9C11"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(tf.int32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 1438,
     "status": "ok",
     "timestamp": 1611602260910,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "WXpAfRd294zm"
   },
   "outputs": [],
   "source": [
    "pred = fwd_prop(x, weights, biases)\n",
    "predictions = tf.argmax(pred, 1)\n",
    "true_labels = tf.argmax(y, 1)\n",
    "correct_predictions = tf.equal(predictions, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1452,
     "status": "ok",
     "timestamp": 1611602304031,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "esQUkNDP-3n9",
    "outputId": "24f88883-1cf0-416e-cd88-cb9c9ef588a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 4, ..., 0, 0, 4]),\n",
       " array([7, 3, 4, ..., 5, 6, 8]),\n",
       " array([False, False,  True, ..., False, False, False]))"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_eval,labels, correct_pred  = sess.run([predictions, true_labels, correct_predictions], feed_dict={x:mnist.train.images, y:mnist.train.labels})\n",
    "predictions_eval,labels,correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1004,
     "status": "ok",
     "timestamp": 1611602308796,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "5_etTHb-94xY",
    "outputId": "7e539a34-3c6d-4240-a290-fd37d1e7d14e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7377"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pred.sum()  # Answer of Train data using random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1155,
     "status": "ok",
     "timestamp": 1611602405311,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "jdK_uhvQ94kR",
    "outputId": "9c45be40-302a-4a9d-a64b-f7ad79741fab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6, 6, 8, ..., 5, 1, 6]),\n",
       " array([7, 2, 1, ..., 4, 5, 6]),\n",
       " array([False, False, False, ..., False, False,  True]))"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_eval,labels, correct_pred  = sess.run([predictions, true_labels, correct_predictions], feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "predictions_eval,labels,correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1611602406749,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "XyXzY5Fr_OBD",
    "outputId": "07dd1cd3-8dec-4b7a-a889-ac36a6ff80e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1258"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pred.sum()  # Answer of Test data using random values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GEZ7kw3_wL-"
   },
   "source": [
    "###**Cost Funtion and Optimiser**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgZLj8_1_y1-"
   },
   "source": [
    "Currently our model is running on random values only. We need to optimise the cost function to get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tensorflow, we dont have to do all of that, we just need to find the cost, and then we will have an optimizer, which will do all of the work for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need the predictions to get the cost and y values to find the cost.  \n",
    "So we will use cross entropy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(tf.int32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have cost of 10 classes, so we will take mean of that.  \n",
    "Logits are the predictions and the labels will be y.  \n",
    "So if we have 10000 images we dont want a 10000 sized array, we need to be one value.  \n",
    "And for each image, we have 10 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hashi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the cost function, we need to basically write and figure out how to optimize cost.  \n",
    "We dont have to write we will use inbuilt optimizer, which will take cost variable from us, figure out that what all variable is this cost dependent upon, and then change this weights to optimize cost.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = forward_propagation(x, weights, biases)\n",
    "predictions = tf.argmax(pred, 1)\n",
    "true_labels = tf.argmax(y, 1)\n",
    "correct_predictions = tf.equal(predictions, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4, 5, 5, ..., 5, 3, 3], dtype=int64),\n",
       " array([7, 3, 4, ..., 5, 6, 8], dtype=int64),\n",
       " array([False, False, False, ...,  True, False, False]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_eval,labels, correct_pred  = sess.run([predictions, true_labels, correct_predictions], feed_dict={x:mnist.train.images, y:mnist.train.labels})\n",
    "predictions_eval,labels,correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7193"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pred.sum()  # Answer of Train data using random values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1066,
     "status": "ok",
     "timestamp": 1611602600778,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "v48bXcJz_mKy",
    "outputId": "09b4bacd-afa7-4e08-ca89-4c53c1861e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-42-680970d64d68>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 1296,
     "status": "ok",
     "timestamp": 1611602601178,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "LK97UQuM_mFy"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimize = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 1155,
     "status": "ok",
     "timestamp": 1611602624708,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "eYEUuixq_mDg"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2459,
     "status": "ok",
     "timestamp": 1611602627687,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "Kbb_pxtR_mBK",
    "outputId": "0cdc89c6-122c-46cc-f56e-9ce6137a25a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1629.7975"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, _ = sess.run([cost,optimize], feed_dict={x:mnist.train.images , y:mnist.train.labels})\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1611602629035,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "NfxgTGRTAHFc",
    "outputId": "663ac7c8-26b5-448d-a9ba-716f8364dfcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1390"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tf.argmax(pred, 1)\n",
    "correct_labels = tf.argmax(y, 1)\n",
    "correct_predictions = tf.equal(predictions, correct_labels)\n",
    "predictions,correct_predictions  = sess.run([predictions, correct_predictions], feed_dict={x:mnist.test.images,\n",
    "                                              y:mnist.test.labels})\n",
    "correct_predictions.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####**Running the Optimizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(tf.int32, [None, n_classes])\n",
    "pred = forward_propagation(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using optimizer we will pass learning rate in it\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimize = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO if we want our optimizer to work on cost, the only thing we need to do is we need to call $->$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimize = optimizer.minimize(cost)\n",
    "# this will try and minimize the cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets create the session and find the cost.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session()\n",
    "sess.run(tf.compat.v1.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1528.6447"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = sess.run(cost, feed_dict={x:mnist.train.images , y:mnist.train.labels})\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are just finding the cost we havent run the optimizer.    \n",
    "Now lets call optimizer as well, so optimize will call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739.87286"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, _ = sess.run([cost,optimize], feed_dict={x:mnist.train.images , y:mnist.train.labels})\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run this, cost will become less and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuB-Cl5fAU-w"
   },
   "source": [
    "After running the optimiser once, we were able to predict more correct values than before. Earlier we predicted 1258 correct labels, and now we predicted 1390 correct labels.\n",
    "\n",
    "Each time we run the optimiser, we will get lower cost and better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmO6MF_EAq4Q"
   },
   "source": [
    "###**Multiple Iterations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIwKxtWkA4kP"
   },
   "source": [
    "Lets run multiple iterations to reduce cost, and reach to better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32507,
     "status": "ok",
     "timestamp": 1611602845656,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "c_mkVKzYAI3u",
    "outputId": "fc94edf6-e7ca-4ba6-d297-1231fb73c664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019.29266\n",
      "700.5243\n",
      "513.6637\n",
      "399.9742\n",
      "328.8933\n",
      "248.9494\n",
      "195.96259\n",
      "173.04364\n",
      "163.69836\n",
      "157.11646\n",
      "146.6288\n",
      "130.57509\n",
      "113.496506\n",
      "100.39235\n",
      "92.59969\n",
      "88.641815\n",
      "85.981415\n",
      "83.05274\n",
      "79.58673\n",
      "75.88236\n",
      "72.39998\n",
      "69.22736\n",
      "66.19135\n",
      "63.288483\n",
      "60.53926\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    c, _ = sess.run([cost,optimize], feed_dict={x:mnist.train.images , y:mnist.train.labels})\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32313,
     "status": "ok",
     "timestamp": 1611602845658,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "_l2XVzQVA1nk",
    "outputId": "548e6426-c88a-4d3c-ba0f-a04274feaea7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8738"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tf.argmax(pred, 1)\n",
    "correct_labels = tf.argmax(y, 1)\n",
    "correct_predictions = tf.equal(predictions, correct_labels)\n",
    "predictions,correct_predictions  = sess.run([predictions, correct_predictions], feed_dict={x:mnist.test.images,\n",
    "                                              y:mnist.test.labels})\n",
    "correct_predictions.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdbtSHQEA_9g"
   },
   "source": [
    "The result has reached to 87.38% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5ROQke-BPFL"
   },
   "source": [
    "We can conduct many experiments to optimise the result. Lets try Batch Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb0KCDLYBVZb"
   },
   "source": [
    "###**Batch Gradient Descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSk5wGjCBmc5"
   },
   "source": [
    "To see the improvement made by Batch Gradient Descent over normal 25 iterarions, we need to re-initlialise the variable, otherwise our optimisation will occur over already optimised values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 1007,
     "status": "ok",
     "timestamp": 1611603072511,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "y0YseqVHBhw6"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72667,
     "status": "ok",
     "timestamp": 1611603144305,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "L_za3_kaBhuo",
    "outputId": "59369e10-e9a2-4ef2-eaf4-7323250f310b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26866.843991994858\n",
      "4872.282126772834\n",
      "2800.5556798107264\n",
      "1910.114575676584\n",
      "1510.8533808255424\n",
      "1169.4314144172788\n",
      "1218.5310681507888\n",
      "957.1686685642795\n",
      "871.3102563868285\n",
      "721.7475954174647\n",
      "766.5503647664465\n",
      "560.4549729592402\n",
      "541.9768450397432\n",
      "598.6273982209284\n",
      "404.3578125140434\n",
      "510.41572584371613\n",
      "395.6451502467838\n",
      "332.8469414837939\n",
      "293.3636789401828\n",
      "306.24514190559603\n",
      "230.5513561649077\n",
      "189.5586250477084\n",
      "205.09118252662302\n",
      "167.48141409801244\n",
      "232.13847664012462\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "for i in range(25):\n",
    "    num_batches = int(mnist.train.num_examples/batch_size) # num_examples says count of values\n",
    "    total_cost = 0\n",
    "    for j in range(num_batches):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)  # sort the images in batch_size.\n",
    "        c, _ = sess.run([cost,optimize], feed_dict={x:batch_x , y:batch_y})\n",
    "        #print(c) -> this will print the cost 25*550 times, to avoid we add each iteration cost in one\n",
    "        total_cost += c\n",
    "    print(total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72139,
     "status": "ok",
     "timestamp": 1611603144307,
     "user": {
      "displayName": "Gaurav Bhatia",
      "photoUrl": "",
      "userId": "05517600112429710610"
     },
     "user_tz": -330
    },
    "id": "0iPrYBklBhsY",
    "outputId": "a353e891-1424-410b-ea1d-a68b9577f140"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9611"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tf.argmax(pred, 1)\n",
    "correct_labels = tf.argmax(y, 1)\n",
    "correct_predictions = tf.equal(predictions, correct_labels)\n",
    "predictions,correct_predictions  = sess.run([predictions, correct_predictions], feed_dict={x:mnist.test.images,\n",
    "                                              y:mnist.test.labels})\n",
    "correct_predictions.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHtYQX7hCOxd"
   },
   "source": [
    "As you can see, we get better results. Our accuracy has reach 96.11%."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tensorflow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
