{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what we want from this data is we call gd(data, learning_rate ) and get the value of m and c\n",
    "## we will not splitting data for training and testing, we can do it later, for now wee are using whole data\n",
    "\n",
    "## we will pass alpha and number of iterations for how many times we want to run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## step_gradient() will get us new m and c which is m' = m -  learning_rate * m_slope , c' = c -  learning_rate * c_slope\n",
    "## where we initialize m_slope to 0.\n",
    "## To calculate the m_slope, we need to write loop which iterates through all datapoints and calculates these values.\n",
    "\n",
    "def step_gradient(points, learning_rate, m, c ):\n",
    "    m_slope = 0\n",
    "    c_slope = 0\n",
    "    \n",
    "    M = len(points)\n",
    "    for i in range(M):  ## This is the loop which iterates through all the values.\n",
    "        \n",
    "        x = points[i,0]   ## This is the value of x which we fetch from 0th column.\n",
    "        y = points[i,1]   ## This is the value of y which we fetch from 1st column.\n",
    "        \n",
    "        \n",
    "        m_slope += (-2/M) * (y - m *x - c)*x    ## calculating m slope inside loop\n",
    "        c_slope += (-2/M) * (y-m*x - c)         ## calculating c slope inside loop\n",
    "    \n",
    "    new_m = m -  learning_rate * m_slope\n",
    "    new_c = c -  learning_rate * c_slope\n",
    "    return new_m, new_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(points, learning_rate, num_iterations):\n",
    "    ## what we are supposed to do in gd is we have to start with random values of m and c.\n",
    "    m = 0\n",
    "    c = 0\n",
    "    ## data has shape (100,2) we have only one feature in our data i.e. one m.\n",
    "    ## what we are supposed to do is we have to run the loop for num_iteration times.\n",
    "    ## in that loop, we have to find the new values of m and c using step_gradient()\n",
    "    ## in which we pass points, learning_rate m and c,\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        m,c = step_gradient(points, learning_rate, m, c)\n",
    "        print(i, 'Cost: ', cost(points, m, c))\n",
    "        \n",
    "    return m,c \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we will add the run function, this will load data for us\n",
    "\n",
    "def run():\n",
    "    data = np.loadtxt('data.csv', delimiter = ',')\n",
    "    learning_rate = 0.0001\n",
    "    num_iterations = 100\n",
    "    m, c = gd(data, learning_rate, num_iterations)\n",
    "    print(m, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(points, m, c):\n",
    "    ## after defining the cost(), we reduce iterations from 1000 to 10, and after every iteration, we print the cost.\n",
    "    ## in gd().\n",
    "    \n",
    "    total_cost = 0\n",
    "    M = len(points)\n",
    "    for i in range(M):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        total_cost += (1/M) * ((y-m*x + c)**2) \n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  86481.1422588648\n",
      "1 Cost:  1371548.9221013477\n",
      "2 Cost:  21763465.24234739\n",
      "3 Cost:  345418286.8309981\n",
      "4 Cost:  5482098867.157961\n",
      "5 Cost:  87006772500.74808\n",
      "6 Cost:  1380886877302.3027\n",
      "7 Cost:  21916108563353.133\n",
      "8 Cost:  347831338448160.94\n",
      "9 Cost:  5520443789204757.0\n",
      "-1489261.2296547107 -29270.969698560042\n"
     ]
    }
   ],
   "source": [
    "run()\n",
    "## we are getting nan because overflow encountered in double_scalars\n",
    "## most likely the issue is with learning rate.\n",
    "## to check, we define cost().\n",
    "\n",
    "## If we look at this, we are actually increasing our cost and that is the reason our m and c is not reaching to conclusion.\n",
    "\n",
    "## so we reduce the learning rate to 0.001 to 0.0001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  1486.719109014127\n",
      "1 Cost:  459.47714645041697\n",
      "2 Cost:  200.47876358969415\n",
      "3 Cost:  135.045804258332\n",
      "4 Cost:  118.44885468137116\n",
      "5 Cost:  114.206009338921\n",
      "6 Cost:  113.1048976990788\n",
      "7 Cost:  112.8110003863775\n",
      "8 Cost:  112.72860577037702\n",
      "9 Cost:  112.70364777690344\n",
      "1.47741737554838 0.029639347874732384\n"
     ]
    }
   ],
   "source": [
    "run()\n",
    "\n",
    "## as we can see,it is much better now the cost is decreasing.\n",
    "## From iteration 7, cost is not very much decreasing.SO we dint really require 1000 iterations.\n",
    "## so lets take 100 iterations and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  1486.719109014127\n",
      "1 Cost:  459.47714645041697\n",
      "2 Cost:  200.47876358969415\n",
      "3 Cost:  135.045804258332\n",
      "4 Cost:  118.44885468137116\n",
      "5 Cost:  114.206009338921\n",
      "6 Cost:  113.1048976990788\n",
      "7 Cost:  112.8110003863775\n",
      "8 Cost:  112.72860577037702\n",
      "9 Cost:  112.70364777690344\n",
      "10 Cost:  112.69526239904837\n",
      "11 Cost:  112.69211286206426\n",
      "12 Cost:  112.6908165149578\n",
      "13 Cost:  112.69025576514841\n",
      "14 Cost:  112.69001547503481\n",
      "15 Cost:  112.68992386994597\n",
      "16 Cost:  112.68990389171476\n",
      "17 Cost:  112.68991914379959\n",
      "18 Cost:  112.68995191979883\n",
      "19 Cost:  112.68999346781617\n",
      "20 Cost:  112.69003942611373\n",
      "21 Cost:  112.69008761173338\n",
      "22 Cost:  112.69013692982458\n",
      "23 Cost:  112.69018683068478\n",
      "24 Cost:  112.69023703817206\n",
      "25 Cost:  112.69028741352952\n",
      "26 Cost:  112.69033788702549\n",
      "27 Cost:  112.6903884236136\n",
      "28 Cost:  112.69043900567955\n",
      "29 Cost:  112.69048962437012\n",
      "30 Cost:  112.6905402752353\n",
      "31 Cost:  112.69059095603824\n",
      "32 Cost:  112.69064166565423\n",
      "33 Cost:  112.69069240351793\n",
      "34 Cost:  112.69074316934456\n",
      "35 Cost:  112.690793962991\n",
      "36 Cost:  112.69084478438474\n",
      "37 Cost:  112.69089563348926\n",
      "38 Cost:  112.69094651028567\n",
      "39 Cost:  112.6909974147643\n",
      "40 Cost:  112.69104834691996\n",
      "41 Cost:  112.69109930674962\n",
      "42 Cost:  112.69115029425161\n",
      "43 Cost:  112.69120130942467\n",
      "44 Cost:  112.69125235226784\n",
      "45 Cost:  112.69130342278036\n",
      "46 Cost:  112.69135452096158\n",
      "47 Cost:  112.69140564681078\n",
      "48 Cost:  112.69145680032732\n",
      "49 Cost:  112.6915079815105\n",
      "50 Cost:  112.69155919035981\n",
      "51 Cost:  112.69161042687445\n",
      "52 Cost:  112.69166169105395\n",
      "53 Cost:  112.69171298289763\n",
      "54 Cost:  112.6917643024048\n",
      "55 Cost:  112.69181564957488\n",
      "56 Cost:  112.69186702440722\n",
      "57 Cost:  112.69191842690111\n",
      "58 Cost:  112.69196985705601\n",
      "59 Cost:  112.69202131487135\n",
      "60 Cost:  112.69207280034637\n",
      "61 Cost:  112.69212431348049\n",
      "62 Cost:  112.69217585427309\n",
      "63 Cost:  112.69222742272352\n",
      "64 Cost:  112.69227901883114\n",
      "65 Cost:  112.69233064259537\n",
      "66 Cost:  112.69238229401549\n",
      "67 Cost:  112.69243397309094\n",
      "68 Cost:  112.69248567982103\n",
      "69 Cost:  112.69253741420522\n",
      "70 Cost:  112.69258917624279\n",
      "71 Cost:  112.69264096593314\n",
      "72 Cost:  112.69269278327563\n",
      "73 Cost:  112.69274462826962\n",
      "74 Cost:  112.69279650091453\n",
      "75 Cost:  112.69284840120964\n",
      "76 Cost:  112.6929003291544\n",
      "77 Cost:  112.6929522847481\n",
      "78 Cost:  112.69300426799018\n",
      "79 Cost:  112.69305627888005\n",
      "80 Cost:  112.69310831741693\n",
      "81 Cost:  112.69316038360024\n",
      "82 Cost:  112.69321247742947\n",
      "83 Cost:  112.6932645989038\n",
      "84 Cost:  112.6933167480227\n",
      "85 Cost:  112.6933689247856\n",
      "86 Cost:  112.69342112919176\n",
      "87 Cost:  112.69347336124059\n",
      "88 Cost:  112.69352562093142\n",
      "89 Cost:  112.69357790826375\n",
      "90 Cost:  112.6936302232368\n",
      "91 Cost:  112.69368256584997\n",
      "92 Cost:  112.69373493610266\n",
      "93 Cost:  112.69378733399415\n",
      "94 Cost:  112.69383975952395\n",
      "95 Cost:  112.69389221269144\n",
      "96 Cost:  112.69394469349574\n",
      "97 Cost:  112.69399720193653\n",
      "98 Cost:  112.69404973801292\n",
      "99 Cost:  112.69410230172446\n",
      "1.4788027175308358 0.035074970592341756\n"
     ]
    }
   ],
   "source": [
    "run()\n",
    "\n",
    "## as we see, cost is decreasing at very low level."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
