{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Scaling states that lets get all our features in uniform range.\n",
    "\n",
    "It depends on feature scaling that we apply.\n",
    "  \n",
    "Ex.  \n",
    "Lets say we are looking at boston dataset.  \n",
    "Lets say we have feature squarefootage and second feature noofbedrooms, now square feature may vary between 1000 - 3000 sqft.  \n",
    "And bedrooms may vary between 1- 5.  \n",
    "Lets understand what will be the impact of having such a different range representing two features.  \n",
    "Generally what will happen is squarefootage will completely overpower noofbedrooms. The importance of noofbedrooms will be far less compared to the importance of squarefootage just because numbers are so high.  \n",
    "For eg lets say I have an algorithm which says that given training data, I have to classify my testing data on basis of what is my nearest neighbour.  \n",
    "To find out the closest neighbour, we need to find distance based on some metrics.One of the metric is Manhattan.  \n",
    "For this problem, we assume it is manhattan metric.  \n",
    "It is defined as  \n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{M}_H  =\\sum_{i=1}^n\\begin{vmatrix}\n",
    "\\mathbf{X}_1^i - \\mathbf{X}_2^i\n",
    "\\end{vmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Lets say testing data is 1500 and 3,  \n",
    "and training data1 = 1600 and 3\n",
    "and training data2 = 1550 and 1.  \n",
    "\n",
    "We can see the closer example to testing data is training data 1 as we can see it has 3 bedrooms and sqft is close.\n",
    "Looking at training data2, whole house is different as it has only 1 bedroom.  \n",
    "But if we apply manhattan distance, distance of training data1 is 100 while the distance of training data2 is 52.  \n",
    "So the closest to testing data is training data2 which is wrong.  \n",
    "\n",
    "This is happening because feature1 is overshadowing feature2.  \n",
    "It makes a lot of sense to do feature scaling.  \n",
    "\n",
    "\n",
    "##### One method to do feature scaling is min max scaling.\n",
    "\n",
    "Lets say we want to get our data in the range of (0,1) and we have our ith feature as $$x^i = (x_1^i, x_2^i, x_3^i .....x_m^i)$$ So to bring it into minimum, first of all subtract it to minimum $$x^i - x_{min()}^i $$, we wanted the minimum to become 0, it has become 0.  \n",
    "We want the maximum to become 1, subtract the complete vector by $$ x_{max()}^i - x_{min()}^i $$  Once we done this, we have made the feature come in the range of 0 to 1.We can apply this to make all feature come in between 0 and 1. \n",
    "\n",
    "\n",
    "### There are various ways to apply feature scaling.Search for it.\n",
    "\n",
    "ref = https://stackoverflow.com/questions/5294955/how-to-scale-down-a-range-of-numbers-with-a-known-min-and-max-value  \n",
    "ref = https://stats.stackexchange.com/questions/70801/how-to-normalize-data-to-0-1-range  \n",
    "ref = https://en.wikipedia.org/wiki/Feature_scaling\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
