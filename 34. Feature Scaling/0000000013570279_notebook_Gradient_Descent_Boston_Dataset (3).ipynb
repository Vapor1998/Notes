{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(X, Y, m, learning_rate):\n",
    "    m_slope = np.zeros(len(X[0]))\n",
    "    for i in range(len(X)):\n",
    "        x = X[i]\n",
    "        y = Y[i]\n",
    "        for j in range(len(x)):\n",
    "            m_slope[j] += (-2/len(X))*(y-sum(m*x))*x[j]\n",
    "    new_m = m - (learning_rate)*(m_slope)\n",
    "    return new_m\n",
    "\n",
    "def cost(x, y, m):\n",
    "    cost = 0\n",
    "    for i in range(len(x)):\n",
    "        cost += (1/len(x))*((y[i]-sum(m*x[i]))**2)\n",
    "    return cost\n",
    "\n",
    "def gd(x, y, learning_rate, num_iterations):\n",
    "    m = np.zeros(len(x[0]))\n",
    "    for i in range(num_iterations):\n",
    "        m = step_gradient(x, y, m, learning_rate)\n",
    "        print(\"itr= \", i, \"cost=\", cost(x, y, m))\n",
    "        \n",
    "    return m\n",
    "\n",
    "def gradient_descent(x,y):\n",
    "    learning_rate = 0.1\n",
    "    num_iterations = 100\n",
    "    x = np.append(x, np.ones(len(x)).reshape(-1,1),axis=1)\n",
    "    m = gd(x, y, learning_rate, num_iterations)\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itr=  0 cost= 375.86932656392213\n",
      "itr=  1 cost= 242.51121799933733\n",
      "itr=  2 cost= 160.5064664365577\n",
      "itr=  3 cost= 109.24543265645516\n",
      "itr=  4 cost= 76.87762541918472\n",
      "itr=  5 cost= 56.29977002236088\n",
      "itr=  6 cost= 43.148707602851914\n",
      "itr=  7 cost= 34.704282014074074\n",
      "itr=  8 cost= 29.254849022508587\n",
      "itr=  9 cost= 25.716961065451247\n",
      "itr=  10 cost= 23.402138644379374\n",
      "itr=  11 cost= 21.87172942699128\n",
      "itr=  12 cost= 20.84572527741592\n",
      "itr=  13 cost= 20.145123322857454\n",
      "itr=  14 cost= 19.65534322648344\n",
      "itr=  15 cost= 19.302946116803952\n",
      "itr=  16 cost= 19.04079179581997\n",
      "itr=  17 cost= 18.838563977416488\n",
      "itr=  18 cost= 18.676716833077858\n",
      "itr=  19 cost= 18.542604900917823\n",
      "itr=  20 cost= 18.428007585848782\n",
      "itr=  21 cost= 18.32754500014809\n",
      "itr=  22 cost= 18.237663763490573\n",
      "itr=  23 cost= 18.155987391250225\n",
      "itr=  24 cost= 18.080899971439088\n",
      "itr=  25 cost= 18.011279157301885\n",
      "itr=  26 cost= 17.946324755864303\n",
      "itr=  27 cost= 17.88544853887733\n",
      "itr=  28 cost= 17.8282032772599\n",
      "itr=  29 cost= 17.774236917192624\n",
      "itr=  30 cost= 17.72326288205533\n",
      "itr=  31 cost= 17.675040726592474\n",
      "itr=  32 cost= 17.6293634449405\n",
      "itr=  33 cost= 17.586049062656326\n",
      "itr=  34 cost= 17.544934993480233\n",
      "itr=  35 cost= 17.505874186268898\n",
      "itr=  36 cost= 17.468732436422293\n",
      "itr=  37 cost= 17.433386459657484\n",
      "itr=  38 cost= 17.399722469241595\n",
      "itr=  39 cost= 17.367635089655597\n",
      "itr=  40 cost= 17.337026498594916\n",
      "itr=  41 cost= 17.307805727055943\n",
      "itr=  42 cost= 17.27988807158467\n",
      "itr=  43 cost= 17.253194588425117\n",
      "itr=  44 cost= 17.22765164941022\n",
      "itr=  45 cost= 17.203190545976234\n",
      "itr=  46 cost= 17.179747131928895\n",
      "itr=  47 cost= 17.15726149836475\n",
      "itr=  48 cost= 17.13567767597629\n",
      "itr=  49 cost= 17.11494336118379\n",
      "itr=  50 cost= 17.095009663353558\n",
      "itr=  51 cost= 17.075830870922974\n",
      "itr=  52 cost= 17.05736423464388\n",
      "itr=  53 cost= 17.039569766437417\n",
      "itr=  54 cost= 17.022410052561636\n",
      "itr=  55 cost= 17.00585007995029\n",
      "itr=  56 cost= 16.989857074707995\n",
      "itr=  57 cost= 16.974400351845723\n",
      "itr=  58 cost= 16.959451175427187\n",
      "itr=  59 cost= 16.944982628367118\n",
      "itr=  60 cost= 16.930969491186175\n",
      "itr=  61 cost= 16.917388129082628\n",
      "itr=  62 cost= 16.90421638672994\n",
      "itr=  63 cost= 16.891433490255586\n",
      "itr=  64 cost= 16.879019955895604\n",
      "itr=  65 cost= 16.866957504858178\n",
      "itr=  66 cost= 16.855228983962675\n",
      "itr=  67 cost= 16.843818291652415\n",
      "itr=  68 cost= 16.832710309008448\n",
      "itr=  69 cost= 16.821890835418138\n",
      "itr=  70 cost= 16.811346528577232\n",
      "itr=  71 cost= 16.80106484852672\n",
      "itr=  72 cost= 16.79103400544736\n",
      "itr=  73 cost= 16.781242910953594\n",
      "itr=  74 cost= 16.771681132647466\n",
      "itr=  75 cost= 16.762338851709746\n",
      "itr=  76 cost= 16.75320682332062\n",
      "itr=  77 cost= 16.74427633971755\n",
      "itr=  78 cost= 16.73553919571058\n",
      "itr=  79 cost= 16.726987656488465\n",
      "itr=  80 cost= 16.718614427560194\n",
      "itr=  81 cost= 16.710412626687294\n",
      "itr=  82 cost= 16.70237575767234\n",
      "itr=  83 cost= 16.6944976858785\n",
      "itr=  84 cost= 16.686772615363264\n",
      "itr=  85 cost= 16.679195067517718\n",
      "itr=  86 cost= 16.67175986111046\n",
      "itr=  87 cost= 16.664462093641337\n",
      "itr=  88 cost= 16.657297123917697\n",
      "itr=  89 cost= 16.65026055577094\n",
      "itr=  90 cost= 16.643348222837453\n",
      "itr=  91 cost= 16.636556174332473\n",
      "itr=  92 cost= 16.629880661751177\n",
      "itr=  93 cost= 16.623318126434434\n",
      "itr=  94 cost= 16.616865187942714\n",
      "itr=  95 cost= 16.610518633183542\n",
      "itr=  96 cost= 16.604275406243097\n",
      "itr=  97 cost= 16.598132598874848\n",
      "itr=  98 cost= 16.59208744160204\n",
      "itr=  99 cost= 16.58613729539343\n",
      "final m : [-1.59728207 -0.28191456 -0.26388331  0.45613625 -1.64969165  1.67793991\n",
      "  0.12882246 -2.71521153  1.73623101 -1.26624525 -1.65795207 -0.0343239\n",
      " -5.59732021  0.26829355  0.13216393  0.16194331  0.45613625 -0.67729638\n",
      "  1.59769035  0.26300462  0.92228077  0.05497136  0.45638304  0.54643182\n",
      " -0.61798739  1.66134485 22.60949868]\n"
     ]
    }
   ],
   "source": [
    "train_data = np.genfromtxt(\"train.csv\", delimiter = \",\")\n",
    "X_train = train_data[:,:-1]\n",
    "Y_train = train_data[:,-1]\n",
    "\n",
    "square = []\n",
    "for i in X_train:\n",
    "    square.append(i**2)\n",
    "square = np.array(square)\n",
    "X_train = np.append(X_train, square, axis = 1)\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "m = gradient_descent(X_train, Y_train)\n",
    "print(\"final m :\",m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.genfromtxt(\"test.csv\", delimiter = \",\")\n",
    "\n",
    "\n",
    "square = []\n",
    "for i in X_test:\n",
    "    square.append(i**2)\n",
    "square = np.array(square)\n",
    "\n",
    "X_test = np.append(X_test, square, axis = 1)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_test = np.append(X_test, np.ones(len(X_test)).reshape(-1, 1), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for i in X_test:\n",
    "    Y_pred = sum(i*m)\n",
    "    predictions.append(Y_pred)\n",
    "    \n",
    "np_predictions = np.array(predictions)\n",
    "\n",
    "np.savetxt(\"predictions.csv\", np_predictions,fmt=\"%.5f\", delimiter=\",\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
